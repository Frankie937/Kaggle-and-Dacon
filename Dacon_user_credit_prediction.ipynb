{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1618385086543,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "KofLsavcfCFI",
    "outputId": "cc95da5a-4fb2-4dc8-ad01-2372ca1326c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntts5788fGxD"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Dacon/data/train.csv\" \"/content/data/train.csv\"\n",
    "!cp \"/content/drive/MyDrive/Dacon/data/test.csv\" \"/content/data/test.csv\"\n",
    "!cp \"/content/drive/MyDrive/Dacon/data/sample_submission.csv\" \"/content/data/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4833,
     "status": "ok",
     "timestamp": 1618385090381,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "CUGMaKx-dAuM",
    "outputId": "289e9ad6-0c9e-48e1-e95f-454a1306ba1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XG_rtqPNdQfd"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/data/train.csv')\n",
    "test = pd.read_csv('/content/data/test.csv')\n",
    "submission = pd.read_csv('/content/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNuIcdXitE5d"
   },
   "source": [
    "### 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4806,
     "status": "ok",
     "timestamp": 1618385090383,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "fVgbndXddaBS",
    "outputId": "3e186945-0add-45b8-d1c0-4cf3bb9f46cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26457, 20)"
      ]
     },
     "execution_count": 604,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4800,
     "status": "ok",
     "timestamp": 1618385090384,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "XFbVQ16odoaU",
    "outputId": "e63522b5-61a7-47fa-bb2b-a188acada476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26457 entries, 0 to 26456\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   index          26457 non-null  int64  \n",
      " 1   gender         26457 non-null  object \n",
      " 2   car            26457 non-null  object \n",
      " 3   reality        26457 non-null  object \n",
      " 4   child_num      26457 non-null  int64  \n",
      " 5   income_total   26457 non-null  float64\n",
      " 6   income_type    26457 non-null  object \n",
      " 7   edu_type       26457 non-null  object \n",
      " 8   family_type    26457 non-null  object \n",
      " 9   house_type     26457 non-null  object \n",
      " 10  DAYS_BIRTH     26457 non-null  int64  \n",
      " 11  DAYS_EMPLOYED  26457 non-null  int64  \n",
      " 12  FLAG_MOBIL     26457 non-null  int64  \n",
      " 13  work_phone     26457 non-null  int64  \n",
      " 14  phone          26457 non-null  int64  \n",
      " 15  email          26457 non-null  int64  \n",
      " 16  occyp_type     18286 non-null  object \n",
      " 17  family_size    26457 non-null  float64\n",
      " 18  begin_month    26457 non-null  float64\n",
      " 19  credit         26457 non-null  float64\n",
      "dtypes: float64(4), int64(8), object(8)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It6o1aN6r40g"
   },
   "source": [
    "### 2. 타겟값에 따라 continuous 피처의 분포도, categorical 피처의 분포도 확인 \n",
    "-> 주요 피처 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4795,
     "status": "ok",
     "timestamp": 1618385090385,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "sGS4p2jFsHd2",
    "outputId": "28e6dada-bd8e-42b4-a373-2d4bb9864cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index            26457\n",
      "child_num            9\n",
      "income_total       249\n",
      "DAYS_BIRTH        6621\n",
      "DAYS_EMPLOYED     3470\n",
      "FLAG_MOBIL           1\n",
      "work_phone           2\n",
      "phone                2\n",
      "email                2\n",
      "family_size         10\n",
      "begin_month         61\n",
      "credit               3\n",
      "dtype: int64\n",
      "categorical feature ['FLAG_MOBIL', 'work_phone', 'phone', 'email', 'credit']\n",
      "continous feature ['income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month', 'child_num', 'family_size']\n"
     ]
    }
   ],
   "source": [
    "# numeric 피처 중에 categorical/continuous 피처 분리\n",
    "num_columns = train.dtypes[train.dtypes != 'object'].index.tolist()\n",
    "unique_len_num = train[num_columns].apply(lambda x : len(x.unique()))\n",
    "print(unique_len_num)\n",
    "# unique_len_num 보면서 분리 \n",
    "continuous = ['index','income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED','begin_month', 'child_num', 'family_size']\n",
    "ordinal = ['family_size', 'child_num'] # 혹시나 해서 ordinal 피처를 다시 분리 해놓기 \n",
    "categorical = [column for column in num_columns if column not in continuous]\n",
    "print('categorical feature', categorical)\n",
    "del continuous[0]\n",
    "print('continous feature', continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTB8L-jT6VD9"
   },
   "outputs": [],
   "source": [
    "def show_hist_by_target(df, columns):\n",
    "    cond_2 = (df['credit'] == 2)\n",
    "    cond_1 = (df['credit'] == 1)\n",
    "    cond_0 = (df['credit'] == 0)\n",
    "    \n",
    "    for column in columns:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4), squeeze=False)\n",
    "        sns.violinplot(x='credit', y=column, data=df, ax=axs[0][0] )\n",
    "        sns.distplot(df[cond_0][column], ax=axs[0][1], label='0', color='blue')\n",
    "        sns.distplot(df[cond_1][column], ax=axs[0][1], label='1', color='red')\n",
    "        sns.distplot(df[cond_2][column], ax=axs[0][1], label='2', color='green')\n",
    "\n",
    "#show_hist_by_target(train, continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4783,
     "status": "ok",
     "timestamp": 1618385090387,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "vOTdxn6fuDKH",
    "outputId": "c1907440-d5db-438e-f431-b506a9fa7ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical feature ['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'FLAG_MOBIL', 'work_phone', 'phone', 'email']\n"
     ]
    }
   ],
   "source": [
    "# object피처를 categorical 피처에 합치기\n",
    "object_columns = train.dtypes[train.dtypes == 'object'].index.tolist()\n",
    "categorical = object_columns + categorical\n",
    "del categorical[-1] # 'credit' 제거 \n",
    "print('categorical feature', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AC1IY5MyUfj"
   },
   "outputs": [],
   "source": [
    "# credit에 따라 categorical 피처들 분포 확인 \n",
    "def show_category_by_target(df, columns):\n",
    "    for column in columns:\n",
    "        chart = sns.catplot(x=column, col=\"credit\", data=df, kind=\"count\")\n",
    "        chart.set_xticklabels(rotation=65)\n",
    "        \n",
    "#show_category_by_target(train, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kytjRMD5D0OV"
   },
   "outputs": [],
   "source": [
    "corr = train[continuous].corr()\n",
    "#sns.heatmap(corr, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UU-d-toqmU9"
   },
   "source": [
    "### 3. train과 test 데이터 합쳐서 피처엔지니어링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXOqQbeZgDa2"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnGApxXRtbn7"
   },
   "source": [
    "#### 3-0. 데이콘 강의_전처리 부분 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5316,
     "status": "ok",
     "timestamp": 1618385090953,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "GOIhCPCshQe0",
    "outputId": "49c9e351-1a3a-44a8-f6bc-441982d947e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 612,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BsX3S0elERF"
   },
   "outputs": [],
   "source": [
    "# 데이터의 모든 컬럼의 고유값의 개수를 확인  \n",
    "unique_len = data.apply(lambda x : len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5307,
     "status": "ok",
     "timestamp": 1618385090967,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "-MBFmeNelW42",
    "outputId": "b7a32eaa-50d9-4e06-cbbc-bc9965d8e4f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index            36457\n",
       "gender               2\n",
       "car                  2\n",
       "reality              2\n",
       "child_num            9\n",
       "income_total       265\n",
       "income_type          5\n",
       "edu_type             5\n",
       "family_type          5\n",
       "house_type           6\n",
       "DAYS_BIRTH        7183\n",
       "DAYS_EMPLOYED     3640\n",
       "FLAG_MOBIL           1\n",
       "work_phone           2\n",
       "phone                2\n",
       "email                2\n",
       "occyp_type          19\n",
       "family_size         10\n",
       "begin_month         61\n",
       "credit               4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 614,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw8VGnOhlYdj"
   },
   "outputs": [],
   "source": [
    "# 고유값 개수 2개 이하/ 2개 초과 10개 이하/ 10개 초과 그룹 3개로 나누기 \n",
    "group1 = unique_len[unique_len <= 2].index # binary \n",
    "group2 = unique_len[(unique_len > 2) & (unique_len <=10)].index # multi \n",
    "group3 = unique_len[unique_len > 10].index # contiunous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "executionInfo": {
     "elapsed": 5289,
     "status": "ok",
     "timestamp": 1618385090973,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "6D-usiJhGQ74",
    "outputId": "9d7d03e2-9049-4f6e-929f-9cb1a4fb9bbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  car  reality  FLAG_MOBIL  work_phone  phone  email\n",
       "0          0    0        0           1           0      0      0\n",
       "1          0    0        1           1           0      0      1\n",
       "2          1    1        1           1           0      1      0\n",
       "3          0    0        1           1           0      1      0\n",
       "4          0    1        1           1           0      0      0\n",
       "...      ...  ...      ...         ...         ...    ...    ...\n",
       "9995       0    1        1           1           1      1      0\n",
       "9996       1    1        1           1           1      0      0\n",
       "9997       0    0        1           1           0      0      0\n",
       "9998       0    1        0           1           0      1      0\n",
       "9999       0    0        1           1           0      0      1\n",
       "\n",
       "[36457 rows x 7 columns]"
      ]
     },
     "execution_count": 616,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <group1> 전처리 \n",
    "data[group1] # 확인 결과, gender, car, reality 문자열값을 0,1로 바꿔주기 \n",
    "data['gender'] = data['gender'].replace(['F', 'M'], [0,1])\n",
    "data['car'] = data['car'].replace(['N','Y'], [0,1])\n",
    "data['reality'] = data['reality'].replace(['N','Y'],[0,1])\n",
    "data[group1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "executionInfo": {
     "elapsed": 5278,
     "status": "ok",
     "timestamp": 1618385090980,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "10M2a_5lLnTe",
    "outputId": "ece2fb7c-0a60-49b7-c073-b535c378d6c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Incomplete higher</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      child_num           income_type  ... family_size credit\n",
       "0             0  Commercial associate  ...         2.0    1.0\n",
       "1             1  Commercial associate  ...         3.0    1.0\n",
       "2             0               Working  ...         2.0    2.0\n",
       "3             0  Commercial associate  ...         2.0    0.0\n",
       "4             0         State servant  ...         2.0    2.0\n",
       "...         ...                   ...  ...         ...    ...\n",
       "9995          0               Working  ...         2.0    NaN\n",
       "9996          0               Working  ...         2.0    NaN\n",
       "9997          0               Working  ...         2.0    NaN\n",
       "9998          0  Commercial associate  ...         2.0    NaN\n",
       "9999          0               Working  ...         2.0    NaN\n",
       "\n",
       "[36457 rows x 7 columns]"
      ]
     },
     "execution_count": 617,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <group2> 전처리\n",
    "data[group2] \n",
    "# child_num 는 따로 처리, 레이블인코딩-income_type, family_type, house_type, 매핑처리(ordinary)-edu_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwvEx0a9Ng7r"
   },
   "outputs": [],
   "source": [
    "# data['child_num'].value_counts().plot.bar()  #child_num의 분포를 보기 (value_counts()와 plot.bar() 이용 )\n",
    "# 3부터 19까지의 값은 거의 존재하지 않는 값이므로 이상치로 취급하고 2 초과인 값을 모두 2로 변경해주기 \n",
    "data.loc[data['child_num'] > 2, 'child_num'] = 2\n",
    "# data['child_num'].value_counts().plot.bar() # 다시 분포 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1xW6T9SOX6x"
   },
   "outputs": [],
   "source": [
    "# sklearn.preprocessing의 LableEncoder 사용하여 income_type, family_type, house_type 처리 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8l8hhHuPmes"
   },
   "outputs": [],
   "source": [
    "data['income_type'] = label_encoder.fit_transform(data['income_type'])\n",
    "data['family_type'] = label_encoder.fit_transform(data['family_type'])\n",
    "data['house_type'] = label_encoder.fit_transform(data['house_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2IZOZgIOEua"
   },
   "outputs": [],
   "source": [
    "# ordinary 컬럼 edu_type 인코딩\n",
    "edu_order = {\n",
    "    'Lower secondary' : 0, # 중학교 미만\n",
    "    'Secondary / secondary special' : 1, #중학교\n",
    "    'Incomplete higher' : 2, # 고등학교 중퇴\n",
    "    'Higher education' : 3, # 고등학교 졸업\n",
    "     'Academic degree' : 4 # 학사 이상\n",
    "}\n",
    "data['edu_type'] = data['edu_type'].map(edu_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "executionInfo": {
     "elapsed": 5254,
     "status": "ok",
     "timestamp": 1618385091003,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "veO_hA7EX1Ve",
    "outputId": "0c641da9-2a4c-4de8-bd48-df580eabc04a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>income_total</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-13899</td>\n",
       "      <td>-4709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>-11380</td>\n",
       "      <td>-1540</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>-19087</td>\n",
       "      <td>-4434</td>\n",
       "      <td>Managers</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-15088</td>\n",
       "      <td>-2092</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>-15037</td>\n",
       "      <td>-2105</td>\n",
       "      <td>Managers</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-18593</td>\n",
       "      <td>-5434</td>\n",
       "      <td>Accountants</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-10886</td>\n",
       "      <td>-1315</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>-21016</td>\n",
       "      <td>-14018</td>\n",
       "      <td>Medicine staff</td>\n",
       "      <td>-55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-16541</td>\n",
       "      <td>-1085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>-9154</td>\n",
       "      <td>-187</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  income_total  ...      occyp_type  begin_month\n",
       "0         0      202500.0  ...             NaN         -6.0\n",
       "1         1      247500.0  ...        Laborers         -5.0\n",
       "2         2      450000.0  ...        Managers        -22.0\n",
       "3         3      202500.0  ...     Sales staff        -37.0\n",
       "4         4      157500.0  ...        Managers        -26.0\n",
       "...     ...           ...  ...             ...          ...\n",
       "9995  36452      202500.0  ...     Accountants        -19.0\n",
       "9996  36453      202500.0  ...        Laborers        -34.0\n",
       "9997  36454      292500.0  ...  Medicine staff        -55.0\n",
       "9998  36455      180000.0  ...             NaN        -33.0\n",
       "9999  36456      270000.0  ...        Laborers        -11.0\n",
       "\n",
       "[36457 rows x 6 columns]"
      ]
     },
     "execution_count": 622,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[group3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFMsAQAMW11F"
   },
   "outputs": [],
   "source": [
    "# <group3> 이상치 평균값으로 대체, 구간화 변수들 새로 생성(피처새로 생성), occyp_type 피처 삭제 \n",
    "# 연속형 변수의 구간화 변수 새로 생성 (연속형 변수를 그대로 넣지 않고 구간화해서 모델에 넣을 경우 더 좋은 성능을 나타내는 알고리즘 모델이 있음)\n",
    "counts, bin_dividers = np.histogram(data['income_total'], bins = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcxsLopnYaaN"
   },
   "outputs": [],
   "source": [
    "pd.cut(data['income_total'], bins=bin_dividers, labels=np.arange(7), include_lowest=True)  # include_lowest=True 는 최솟값도 구간에 포함시키기 위해서 하는 것\n",
    "# pd.cut()의 반환 자료형은 'category'이다.(Series와는 다름) 'int'로 바꿔주기 위해 pd.factorize() 사용하기 \n",
    "pd.factorize(pd.cut(data['income_total'], bins=bin_dividers, labels=[i for i in range(7)], include_lowest=True))\n",
    "data['income_total_bin'] = pd.factorize(pd.cut(data['income_total'], bins=bin_dividers, include_lowest=True, labels=[i for i in range(7)]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5241,
     "status": "ok",
     "timestamp": 1618385091022,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "9KGxj4PbDarz",
    "outputId": "26bd7011-cddd-48ed-a166-6d1a33724088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 365243    6135\n",
       "-401         78\n",
       "-1539        64\n",
       "-200         63\n",
       "-2087        61\n",
       "           ... \n",
       "-3640         1\n",
       "-5717         1\n",
       "-4420         1\n",
       "-2203         1\n",
       "-2024         1\n",
       "Name: DAYS_EMPLOYED, Length: 3640, dtype: int64"
      ]
     },
     "execution_count": 625,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DAYS_EMPLOYED'].value_counts()\n",
    "# DAYS_EMPLOYED의 값에서 365243 값이 이상함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEbZxN8tEE1T"
   },
   "outputs": [],
   "source": [
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].replace(365243, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrpBO-AzDumC"
   },
   "outputs": [],
   "source": [
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].fillna(data['DAYS_EMPLOYED'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8WDrgpUYQP5"
   },
   "outputs": [],
   "source": [
    "# 연속형 변수를 구간화하는 함수 만들고, 함수 이용하여 구간화 변수 3개 생성  \n",
    "def make_bin(array, n):\n",
    "  array = -array # DAYS_BIRTH, DAYS_EMPLOYED, begin_month 가 마이너스라서 \n",
    "  _, bin_dividers = np.histogram(array, bins=n)\n",
    "  categories = pd.cut(array, bins=bin_dividers, include_lowest=True, labels=[i for i in range(n)])\n",
    "  bined_array = pd.factorize(categories)[0]\n",
    "  return bined_array\n",
    "\n",
    "data['DAYS_BIRTH_BIN'] = make_bin(data['DAYS_BIRTH'], 10)\n",
    "data['DAYS_EMPLOYED_BIN'] = make_bin(data['DAYS_EMPLOYED'], 6)\n",
    "data['begin_month_bin'] = make_bin(data['begin_month'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0j4C18dC3No"
   },
   "outputs": [],
   "source": [
    "data.drop('occyp_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixZxI8-Wsz11"
   },
   "source": [
    "#### 3-1. object 피처들 레이블 인코딩(3-0 하면 안해도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu_d6z0qQiGh"
   },
   "outputs": [],
   "source": [
    "# data['edu_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wVrRqBpP8sq"
   },
   "outputs": [],
   "source": [
    "# # ordinary 한 피처 'edu_type'은 레이블 인코딩 말고 map으로 인코딩 \n",
    "# edu_order = {\n",
    "#     'Lower secondary' : 0, # 중학교 미만\n",
    "#     'Secondary / secondary special' : 1, #중학교\n",
    "#     'Incomplete higher' : 2, # 고등학교 중퇴\n",
    "#     'Higher education' : 3, # 고등학교 졸업\n",
    "#      'Academic degree' : 4 # 학사 이상\n",
    "# }\n",
    "# data.edu_type = data.edu_type.map(edu_order)\n",
    "# data['edu_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKamwdoBl6o3"
   },
   "outputs": [],
   "source": [
    "# object_columns = data.dtypes[data.dtypes=='object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQUAOLyaqR6z"
   },
   "outputs": [],
   "source": [
    "# for column in object_columns:\n",
    "#   data[column] = pd.factorize(data[column])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nIvPy4LFGoB"
   },
   "source": [
    "#### 3-2. 주요 피처 엔지니어링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJzQKmPcFZG1"
   },
   "outputs": [],
   "source": [
    "# # baseline은 피처 가공 없이 한 것 \n",
    "# # submission_try01 피처가공 함수\n",
    "# def get_try01 (data):\n",
    "#   #  DAYS_BIRTH, DAYS_EMPLOYED 비율로 소득 Feature 가공. \n",
    "#   data['EMPLOYED_BIRTH_RATIO'] = data['DAYS_EMPLOYED']/data['DAYS_BIRTH']\n",
    "#   data['INCOME_EMPLOYED_RATIO'] = data['income_total']/data['DAYS_EMPLOYED']\n",
    "#   data['INCOME_BIRTH_RATIO'] = data['income_total']/data['DAYS_BIRTH']\n",
    "#   # 가족수를 고려한 가처분 소득 피처 가공. \n",
    "#   data['CNT_CHILD_INCOME_RATIO'] = data['income_total']/data['child_num']\n",
    "#   data['CNT_FAM_INCOME_RATIO'] = data['income_total']/data['family_size']\n",
    "#   return data \n",
    "\n",
    "# # try_01_valid = 0.7368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNAlM1uwBRCQ"
   },
   "outputs": [],
   "source": [
    "# submission_try02 피처가공 함수\n",
    "def get_try02 (data):\n",
    "  #  DAYS_BIRTH, DAYS_EMPLOYED 비율로 소득 Feature 가공. \n",
    "  data['EMPLOYED_BIRTH_RATIO'] = data['DAYS_EMPLOYED']/data['DAYS_BIRTH']\n",
    "  data['INCOME_EMPLOYED_RATIO'] = data['income_total']/data['DAYS_EMPLOYED']\n",
    "  data['INCOME_BIRTH_RATIO'] = data['income_total']/data['DAYS_BIRTH']\n",
    "  # 가족수와 자녀수 mean, sum 피처 가공\n",
    "  # data['FAM_CHILD_MEAN'] = data[['child_num', 'family_size']].mean(axis=1)\n",
    "  data['FAM_CHILD_SUM'] = data[['child_num', 'family_size']].sum(axis=1)\n",
    "  # 가족수를 고려한 가처분 소득 피처 가공. \n",
    "  # data['CNT_CHILD_INCOME_RATIO'] = data['income_total']/data['child_num']\n",
    "  data['CNT_FAM_INCOME_RATIO'] = data['income_total']/data['family_size']\n",
    "  # 소유 여부(0/1의 2개 category피처들)와 교육수준 관련 피처들 mean, sum 피처 가공 \n",
    "  data['HAVE_OR_NOT_MEAN'] =data[['car','reality','work_phone','phone','email','edu_type']].mean(axis=1)\n",
    "  #data['HAVE_OR_NOT_SUM'] =data[['car','reality','work_phone','phone','email', 'edu_type']].sum(axis=1)\n",
    "\n",
    "  #새로 추가(4/14)\n",
    "  data['INCOME_HAVE_OR_NOT_RATIO'] = data['income_total']/data['HAVE_OR_NOT_MEAN']\n",
    "  # data['DAYS_SUM'] = data[['DAYS_BIRTH_BIN', 'DAYS_EMPLOYED_BIN', 'begin_month']].sum(axis=1)\n",
    "  # data['INCOME_DAYS_SUM_RATIO'] = data['income_total'] / data[['DAYS_BIRTH_BIN', 'DAYS_EMPLOYED_BIN', 'begin_month']].sum(axis=1)\n",
    "\n",
    "  # 필요없는 피처 삭제 \n",
    "  # data = data.drop(['work_phone', 'phone', 'email', 'DAYS_EMPLOYED_BIN', 'begin_month_bin'], axis=1)\n",
    "\n",
    "  return data \n",
    "\n",
    "#try_02_valid = 0.7347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDijYnbKBaW1"
   },
   "outputs": [],
   "source": [
    "data = get_try02(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8-eEm3sRDao"
   },
   "source": [
    "### 4. train-test 분리하고 학습/feature_importance 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5449,
     "status": "ok",
     "timestamp": 1618385091333,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "Ap_brJaARJ4L",
    "outputId": "6279fc26-daef-4774-ba61-ac62476b008e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 30), (10000, 29))"
      ]
     },
     "execution_count": 637,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data[~data['credit'].isnull()]\n",
    "test = data[data['credit'].isnull()]\n",
    "test = test.drop('credit', axis=1)\n",
    "train.shape , test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5436,
     "status": "ok",
     "timestamp": 1618385091334,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "NUmQme94SJII",
    "outputId": "7c1cd2f6-638c-426b-aa7c-f894b2c0f2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18519, 28), (7938, 28))"
      ]
     },
     "execution_count": 638,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습데이터를 다시 학습-검증데이터로 분리 (for 교차검증)\n",
    "ftr_train = train.drop(['index','credit'], axis=1)\n",
    "target_train = train['credit']\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr_train, target_train, test_size=0.3, random_state=156)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24726,
     "status": "ok",
     "timestamp": 1618385110637,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "5oBprd3lTOvT",
    "outputId": "968de85b-155b-4579-e494-21489ecba8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.767718\ttraining's multi_logloss: 0.767718\tvalid_1's multi_logloss: 0.792332\tvalid_1's multi_logloss: 0.792332\n",
      "[200]\ttraining's multi_logloss: 0.727132\ttraining's multi_logloss: 0.727132\tvalid_1's multi_logloss: 0.775416\tvalid_1's multi_logloss: 0.775416\n",
      "[300]\ttraining's multi_logloss: 0.697079\ttraining's multi_logloss: 0.697079\tvalid_1's multi_logloss: 0.764382\tvalid_1's multi_logloss: 0.764382\n",
      "[400]\ttraining's multi_logloss: 0.671656\ttraining's multi_logloss: 0.671656\tvalid_1's multi_logloss: 0.756421\tvalid_1's multi_logloss: 0.756421\n",
      "[500]\ttraining's multi_logloss: 0.649728\ttraining's multi_logloss: 0.649728\tvalid_1's multi_logloss: 0.751029\tvalid_1's multi_logloss: 0.751029\n",
      "[600]\ttraining's multi_logloss: 0.629556\ttraining's multi_logloss: 0.629556\tvalid_1's multi_logloss: 0.746193\tvalid_1's multi_logloss: 0.746193\n",
      "[700]\ttraining's multi_logloss: 0.610229\ttraining's multi_logloss: 0.610229\tvalid_1's multi_logloss: 0.741415\tvalid_1's multi_logloss: 0.741415\n",
      "[800]\ttraining's multi_logloss: 0.592351\ttraining's multi_logloss: 0.592351\tvalid_1's multi_logloss: 0.737687\tvalid_1's multi_logloss: 0.737687\n",
      "[900]\ttraining's multi_logloss: 0.576702\ttraining's multi_logloss: 0.576702\tvalid_1's multi_logloss: 0.734505\tvalid_1's multi_logloss: 0.734505\n",
      "[1000]\ttraining's multi_logloss: 0.561584\ttraining's multi_logloss: 0.561584\tvalid_1's multi_logloss: 0.732422\tvalid_1's multi_logloss: 0.732422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's multi_logloss: 0.561584\ttraining's multi_logloss: 0.561584\tvalid_1's multi_logloss: 0.732422\tvalid_1's multi_logloss: 0.732422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.02, max_depth=12,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=1000, n_jobs=-1, num_leaves=32, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=-1,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0,\n",
       "               verbose=-1)"
      ]
     },
     "execution_count": 639,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LGBMClassifier 학습\n",
    "clf = LGBMClassifier(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        subsample=0.8,\n",
    "        max_depth=12,\n",
    "        silent=-1,\n",
    "        verbose=-1\n",
    "        )\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "        early_stopping_rounds= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "executionInfo": {
     "elapsed": 1352,
     "status": "ok",
     "timestamp": 1618385129037,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "FVCeqWZyVOrr",
    "outputId": "51c5e299-61c8-4332-9642-f2a073f51fb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f10a9898c50>"
      ]
     },
     "execution_count": 640,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "plot_importance(clf, figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtI2A1-EBcuO"
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test.drop('index', axis=1))\n",
    "submission.iloc[:, 1:] = predictions \n",
    "submission.to_csv('submission_try02_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0o6nFh3TlEJ"
   },
   "source": [
    "### 5. 하이퍼파라미터 튜닝 후 학습/검증/예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cFnm2I-CO3P"
   },
   "source": [
    "#### 5-1 Bayesian Optimization 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBaLJ1q-VFz_"
   },
   "outputs": [],
   "source": [
    "# 베이지안 옵티마이저 사용하여 하이퍼파라미터 튜닝 \n",
    "bayesian_params = {\n",
    "    'max_depth': (6, 16), \n",
    "    'num_leaves': (24, 64), \n",
    "    'min_child_samples': (10, 200), \n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha': (0.01, 50) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-JLEfUAJCiT"
   },
   "outputs": [],
   "source": [
    "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
    "    params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
    "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': int(round(num_leaves)), \n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample': max(min(subsample, 1), 0), \n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'max_bin':  max(int(round(max_bin)),10),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_proba = lgb_model.predict(valid_x)\n",
    "    accuracy = accuracy_score(valid_y, valid_proba)\n",
    "\n",
    "    return accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392345,
     "status": "ok",
     "timestamp": 1618386281994,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "hOhEXnk7JhOd",
    "outputId": "5c451c06-2fb2-4d63-a38c-85cb6ae5ad01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.811789\ttraining's multi_logloss: 0.811789\tvalid_1's multi_logloss: 0.814901\tvalid_1's multi_logloss: 0.814901\n",
      "[200]\ttraining's multi_logloss: 0.789082\ttraining's multi_logloss: 0.789082\tvalid_1's multi_logloss: 0.800918\tvalid_1's multi_logloss: 0.800918\n",
      "[300]\ttraining's multi_logloss: 0.774473\ttraining's multi_logloss: 0.774473\tvalid_1's multi_logloss: 0.793984\tvalid_1's multi_logloss: 0.793984\n",
      "[400]\ttraining's multi_logloss: 0.762966\ttraining's multi_logloss: 0.762966\tvalid_1's multi_logloss: 0.789123\tvalid_1's multi_logloss: 0.789123\n",
      "[500]\ttraining's multi_logloss: 0.754094\ttraining's multi_logloss: 0.754094\tvalid_1's multi_logloss: 0.785853\tvalid_1's multi_logloss: 0.785853\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.754094\ttraining's multi_logloss: 0.754094\tvalid_1's multi_logloss: 0.785853\tvalid_1's multi_logloss: 0.785853\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6945  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 49.84   \u001b[0m | \u001b[0m 21.88   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.793521\ttraining's multi_logloss: 0.793521\tvalid_1's multi_logloss: 0.808074\tvalid_1's multi_logloss: 0.808074\n",
      "[200]\ttraining's multi_logloss: 0.760301\ttraining's multi_logloss: 0.760301\tvalid_1's multi_logloss: 0.790167\tvalid_1's multi_logloss: 0.790167\n",
      "[300]\ttraining's multi_logloss: 0.739011\ttraining's multi_logloss: 0.739011\tvalid_1's multi_logloss: 0.781927\tvalid_1's multi_logloss: 0.781927\n",
      "[400]\ttraining's multi_logloss: 0.721549\ttraining's multi_logloss: 0.721549\tvalid_1's multi_logloss: 0.776113\tvalid_1's multi_logloss: 0.776113\n",
      "[500]\ttraining's multi_logloss: 0.706732\ttraining's multi_logloss: 0.706732\tvalid_1's multi_logloss: 0.771449\tvalid_1's multi_logloss: 0.771449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.706732\ttraining's multi_logloss: 0.706732\tvalid_1's multi_logloss: 0.771449\tvalid_1's multi_logloss: 0.771449\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6978  \u001b[0m | \u001b[95m 0.6917  \u001b[0m | \u001b[95m 397.9   \u001b[0m | \u001b[95m 11.29   \u001b[0m | \u001b[95m 117.9   \u001b[0m | \u001b[95m 46.35   \u001b[0m | \u001b[95m 26.84   \u001b[0m | \u001b[95m 4.366   \u001b[0m | \u001b[95m 0.2032  \u001b[0m | \u001b[95m 0.9163  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.777446\ttraining's multi_logloss: 0.777446\tvalid_1's multi_logloss: 0.79927\tvalid_1's multi_logloss: 0.79927\n",
      "[200]\ttraining's multi_logloss: 0.734974\ttraining's multi_logloss: 0.734974\tvalid_1's multi_logloss: 0.780919\tvalid_1's multi_logloss: 0.780919\n",
      "[300]\ttraining's multi_logloss: 0.704165\ttraining's multi_logloss: 0.704165\tvalid_1's multi_logloss: 0.771074\tvalid_1's multi_logloss: 0.771074\n",
      "[400]\ttraining's multi_logloss: 0.680329\ttraining's multi_logloss: 0.680329\tvalid_1's multi_logloss: 0.763937\tvalid_1's multi_logloss: 0.763937\n",
      "[500]\ttraining's multi_logloss: 0.660272\ttraining's multi_logloss: 0.660272\tvalid_1's multi_logloss: 0.758745\tvalid_1's multi_logloss: 0.758745\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.660272\ttraining's multi_logloss: 0.660272\tvalid_1's multi_logloss: 0.758745\tvalid_1's multi_logloss: 0.758745\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7024  \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 15.79   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 55.22   \u001b[0m | \u001b[95m 5.923   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.809958\ttraining's multi_logloss: 0.809958\tvalid_1's multi_logloss: 0.811781\tvalid_1's multi_logloss: 0.811781\n",
      "[200]\ttraining's multi_logloss: 0.792197\ttraining's multi_logloss: 0.792197\tvalid_1's multi_logloss: 0.801665\tvalid_1's multi_logloss: 0.801665\n",
      "[300]\ttraining's multi_logloss: 0.781548\ttraining's multi_logloss: 0.781548\tvalid_1's multi_logloss: 0.796477\tvalid_1's multi_logloss: 0.796477\n",
      "[400]\ttraining's multi_logloss: 0.774134\ttraining's multi_logloss: 0.774134\tvalid_1's multi_logloss: 0.793393\tvalid_1's multi_logloss: 0.793393\n",
      "[500]\ttraining's multi_logloss: 0.768775\ttraining's multi_logloss: 0.768775\tvalid_1's multi_logloss: 0.791665\tvalid_1's multi_logloss: 0.791665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.768775\ttraining's multi_logloss: 0.768775\tvalid_1's multi_logloss: 0.791665\tvalid_1's multi_logloss: 0.791665\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6945  \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 42.25   \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.816866\ttraining's multi_logloss: 0.816866\tvalid_1's multi_logloss: 0.816294\tvalid_1's multi_logloss: 0.816294\n",
      "[200]\ttraining's multi_logloss: 0.801314\ttraining's multi_logloss: 0.801314\tvalid_1's multi_logloss: 0.805155\tvalid_1's multi_logloss: 0.805155\n",
      "[300]\ttraining's multi_logloss: 0.793553\ttraining's multi_logloss: 0.793553\tvalid_1's multi_logloss: 0.800494\tvalid_1's multi_logloss: 0.800494\n",
      "[400]\ttraining's multi_logloss: 0.78891\ttraining's multi_logloss: 0.78891\tvalid_1's multi_logloss: 0.798299\tvalid_1's multi_logloss: 0.798299\n",
      "[500]\ttraining's multi_logloss: 0.785713\ttraining's multi_logloss: 0.785713\tvalid_1's multi_logloss: 0.797091\tvalid_1's multi_logloss: 0.797091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.785713\ttraining's multi_logloss: 0.785713\tvalid_1's multi_logloss: 0.797091\tvalid_1's multi_logloss: 0.797091\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6951  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 312.3   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 41.48   \u001b[0m | \u001b[0m 34.88   \u001b[0m | \u001b[0m 0.6032  \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.801852\ttraining's multi_logloss: 0.801852\tvalid_1's multi_logloss: 0.810056\tvalid_1's multi_logloss: 0.810056\n",
      "[200]\ttraining's multi_logloss: 0.773371\ttraining's multi_logloss: 0.773371\tvalid_1's multi_logloss: 0.794891\tvalid_1's multi_logloss: 0.794891\n",
      "[300]\ttraining's multi_logloss: 0.754772\ttraining's multi_logloss: 0.754772\tvalid_1's multi_logloss: 0.786672\tvalid_1's multi_logloss: 0.786672\n",
      "[400]\ttraining's multi_logloss: 0.740262\ttraining's multi_logloss: 0.740262\tvalid_1's multi_logloss: 0.781179\tvalid_1's multi_logloss: 0.781179\n",
      "[500]\ttraining's multi_logloss: 0.729714\ttraining's multi_logloss: 0.729714\tvalid_1's multi_logloss: 0.777711\tvalid_1's multi_logloss: 0.777711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.729714\ttraining's multi_logloss: 0.729714\tvalid_1's multi_logloss: 0.777711\tvalid_1's multi_logloss: 0.777711\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6963  \u001b[0m | \u001b[0m 0.8284  \u001b[0m | \u001b[0m 495.1   \u001b[0m | \u001b[0m 8.683   \u001b[0m | \u001b[0m 21.22   \u001b[0m | \u001b[0m 3.258   \u001b[0m | \u001b[0m 62.56   \u001b[0m | \u001b[0m 19.59   \u001b[0m | \u001b[0m 1.486   \u001b[0m | \u001b[0m 0.7496  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.820381\ttraining's multi_logloss: 0.820381\tvalid_1's multi_logloss: 0.820204\tvalid_1's multi_logloss: 0.820204\n",
      "[200]\ttraining's multi_logloss: 0.803003\ttraining's multi_logloss: 0.803003\tvalid_1's multi_logloss: 0.807052\tvalid_1's multi_logloss: 0.807052\n",
      "[300]\ttraining's multi_logloss: 0.793378\ttraining's multi_logloss: 0.793378\tvalid_1's multi_logloss: 0.801268\tvalid_1's multi_logloss: 0.801268\n",
      "[400]\ttraining's multi_logloss: 0.786783\ttraining's multi_logloss: 0.786783\tvalid_1's multi_logloss: 0.797987\tvalid_1's multi_logloss: 0.797987\n",
      "[500]\ttraining's multi_logloss: 0.781968\ttraining's multi_logloss: 0.781968\tvalid_1's multi_logloss: 0.79601\tvalid_1's multi_logloss: 0.79601\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.781968\ttraining's multi_logloss: 0.781968\tvalid_1's multi_logloss: 0.79601\tvalid_1's multi_logloss: 0.79601\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6951  \u001b[0m | \u001b[0m 0.6299  \u001b[0m | \u001b[0m 489.8   \u001b[0m | \u001b[0m 15.31   \u001b[0m | \u001b[0m 199.0   \u001b[0m | \u001b[0m 45.2    \u001b[0m | \u001b[0m 51.84   \u001b[0m | \u001b[0m 29.76   \u001b[0m | \u001b[0m 4.925   \u001b[0m | \u001b[0m 0.5147  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.77438\ttraining's multi_logloss: 0.77438\tvalid_1's multi_logloss: 0.803241\tvalid_1's multi_logloss: 0.803241\n",
      "[200]\ttraining's multi_logloss: 0.730332\ttraining's multi_logloss: 0.730332\tvalid_1's multi_logloss: 0.784497\tvalid_1's multi_logloss: 0.784497\n",
      "[300]\ttraining's multi_logloss: 0.699694\ttraining's multi_logloss: 0.699694\tvalid_1's multi_logloss: 0.774739\tvalid_1's multi_logloss: 0.774739\n",
      "[400]\ttraining's multi_logloss: 0.675676\ttraining's multi_logloss: 0.675676\tvalid_1's multi_logloss: 0.767504\tvalid_1's multi_logloss: 0.767504\n",
      "[500]\ttraining's multi_logloss: 0.654377\ttraining's multi_logloss: 0.654377\tvalid_1's multi_logloss: 0.762302\tvalid_1's multi_logloss: 0.762302\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.654377\ttraining's multi_logloss: 0.654377\tvalid_1's multi_logloss: 0.762302\tvalid_1's multi_logloss: 0.762302\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7027  \u001b[0m | \u001b[95m 0.6347  \u001b[0m | \u001b[95m 35.69   \u001b[0m | \u001b[95m 13.42   \u001b[0m | \u001b[95m 179.4   \u001b[0m | \u001b[95m 22.59   \u001b[0m | \u001b[95m 63.25   \u001b[0m | \u001b[95m 0.5422  \u001b[0m | \u001b[95m 2.012   \u001b[0m | \u001b[95m 0.6681  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.807447\ttraining's multi_logloss: 0.807447\tvalid_1's multi_logloss: 0.818043\tvalid_1's multi_logloss: 0.818043\n",
      "[200]\ttraining's multi_logloss: 0.778852\ttraining's multi_logloss: 0.778852\tvalid_1's multi_logloss: 0.801582\tvalid_1's multi_logloss: 0.801582\n",
      "[300]\ttraining's multi_logloss: 0.760105\ttraining's multi_logloss: 0.760105\tvalid_1's multi_logloss: 0.793111\tvalid_1's multi_logloss: 0.793111\n",
      "[400]\ttraining's multi_logloss: 0.745956\ttraining's multi_logloss: 0.745956\tvalid_1's multi_logloss: 0.787692\tvalid_1's multi_logloss: 0.787692\n",
      "[500]\ttraining's multi_logloss: 0.734392\ttraining's multi_logloss: 0.734392\tvalid_1's multi_logloss: 0.784182\tvalid_1's multi_logloss: 0.784182\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.734392\ttraining's multi_logloss: 0.734392\tvalid_1's multi_logloss: 0.784182\tvalid_1's multi_logloss: 0.784182\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6958  \u001b[0m | \u001b[0m 0.5191  \u001b[0m | \u001b[0m 14.48   \u001b[0m | \u001b[0m 11.14   \u001b[0m | \u001b[0m 174.3   \u001b[0m | \u001b[0m 2.786   \u001b[0m | \u001b[0m 26.61   \u001b[0m | \u001b[0m 2.459   \u001b[0m | \u001b[0m 4.393   \u001b[0m | \u001b[0m 0.7535  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.799976\ttraining's multi_logloss: 0.799976\tvalid_1's multi_logloss: 0.807372\tvalid_1's multi_logloss: 0.807372\n",
      "[200]\ttraining's multi_logloss: 0.777168\ttraining's multi_logloss: 0.777168\tvalid_1's multi_logloss: 0.795824\tvalid_1's multi_logloss: 0.795824\n",
      "[300]\ttraining's multi_logloss: 0.761101\ttraining's multi_logloss: 0.761101\tvalid_1's multi_logloss: 0.789497\tvalid_1's multi_logloss: 0.789497\n",
      "[400]\ttraining's multi_logloss: 0.749042\ttraining's multi_logloss: 0.749042\tvalid_1's multi_logloss: 0.785129\tvalid_1's multi_logloss: 0.785129\n",
      "[500]\ttraining's multi_logloss: 0.737544\ttraining's multi_logloss: 0.737544\tvalid_1's multi_logloss: 0.78145\tvalid_1's multi_logloss: 0.78145\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.737544\ttraining's multi_logloss: 0.737544\tvalid_1's multi_logloss: 0.78145\tvalid_1's multi_logloss: 0.78145\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6949  \u001b[0m | \u001b[0m 0.9182  \u001b[0m | \u001b[0m 392.8   \u001b[0m | \u001b[0m 6.154   \u001b[0m | \u001b[0m 195.2   \u001b[0m | \u001b[0m 4.086   \u001b[0m | \u001b[0m 61.7    \u001b[0m | \u001b[0m 6.406   \u001b[0m | \u001b[0m 1.545   \u001b[0m | \u001b[0m 0.9429  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.757284\ttraining's multi_logloss: 0.757284\tvalid_1's multi_logloss: 0.791746\tvalid_1's multi_logloss: 0.791746\n",
      "[200]\ttraining's multi_logloss: 0.707191\ttraining's multi_logloss: 0.707191\tvalid_1's multi_logloss: 0.772004\tvalid_1's multi_logloss: 0.772004\n",
      "[300]\ttraining's multi_logloss: 0.670842\ttraining's multi_logloss: 0.670842\tvalid_1's multi_logloss: 0.760296\tvalid_1's multi_logloss: 0.760296\n",
      "[400]\ttraining's multi_logloss: 0.641564\ttraining's multi_logloss: 0.641564\tvalid_1's multi_logloss: 0.752404\tvalid_1's multi_logloss: 0.752404\n",
      "[500]\ttraining's multi_logloss: 0.617426\ttraining's multi_logloss: 0.617426\tvalid_1's multi_logloss: 0.747295\tvalid_1's multi_logloss: 0.747295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.617426\ttraining's multi_logloss: 0.617426\tvalid_1's multi_logloss: 0.747295\tvalid_1's multi_logloss: 0.747295\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.709   \u001b[0m | \u001b[95m 0.9113  \u001b[0m | \u001b[95m 139.1   \u001b[0m | \u001b[95m 15.94   \u001b[0m | \u001b[95m 25.45   \u001b[0m | \u001b[95m 24.62   \u001b[0m | \u001b[95m 60.8    \u001b[0m | \u001b[95m 2.607   \u001b[0m | \u001b[95m 3.726   \u001b[0m | \u001b[95m 0.5292  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.767917\ttraining's multi_logloss: 0.767917\tvalid_1's multi_logloss: 0.798422\tvalid_1's multi_logloss: 0.798422\n",
      "[200]\ttraining's multi_logloss: 0.725147\ttraining's multi_logloss: 0.725147\tvalid_1's multi_logloss: 0.782931\tvalid_1's multi_logloss: 0.782931\n",
      "[300]\ttraining's multi_logloss: 0.693402\ttraining's multi_logloss: 0.693402\tvalid_1's multi_logloss: 0.774163\tvalid_1's multi_logloss: 0.774163\n",
      "[400]\ttraining's multi_logloss: 0.667419\ttraining's multi_logloss: 0.667419\tvalid_1's multi_logloss: 0.768178\tvalid_1's multi_logloss: 0.768178\n",
      "[500]\ttraining's multi_logloss: 0.644827\ttraining's multi_logloss: 0.644827\tvalid_1's multi_logloss: 0.763215\tvalid_1's multi_logloss: 0.763215\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.644827\ttraining's multi_logloss: 0.644827\tvalid_1's multi_logloss: 0.763215\tvalid_1's multi_logloss: 0.763215\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7036  \u001b[0m | \u001b[0m 0.98    \u001b[0m | \u001b[0m 11.82   \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 43.37   \u001b[0m | \u001b[0m 30.93   \u001b[0m | \u001b[0m 60.49   \u001b[0m | \u001b[0m 0.4702  \u001b[0m | \u001b[0m 2.889   \u001b[0m | \u001b[0m 0.7434  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.767076\ttraining's multi_logloss: 0.767076\tvalid_1's multi_logloss: 0.798708\tvalid_1's multi_logloss: 0.798708\n",
      "[200]\ttraining's multi_logloss: 0.718558\ttraining's multi_logloss: 0.718558\tvalid_1's multi_logloss: 0.777666\tvalid_1's multi_logloss: 0.777666\n",
      "[300]\ttraining's multi_logloss: 0.687533\ttraining's multi_logloss: 0.687533\tvalid_1's multi_logloss: 0.767217\tvalid_1's multi_logloss: 0.767217\n",
      "[400]\ttraining's multi_logloss: 0.664985\ttraining's multi_logloss: 0.664985\tvalid_1's multi_logloss: 0.760187\tvalid_1's multi_logloss: 0.760187\n",
      "[500]\ttraining's multi_logloss: 0.64504\ttraining's multi_logloss: 0.64504\tvalid_1's multi_logloss: 0.754472\tvalid_1's multi_logloss: 0.754472\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.64504\ttraining's multi_logloss: 0.64504\tvalid_1's multi_logloss: 0.754472\tvalid_1's multi_logloss: 0.754472\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7062  \u001b[0m | \u001b[0m 0.6717  \u001b[0m | \u001b[0m 423.7   \u001b[0m | \u001b[0m 14.78   \u001b[0m | \u001b[0m 17.68   \u001b[0m | \u001b[0m 48.88   \u001b[0m | \u001b[0m 59.46   \u001b[0m | \u001b[0m 1.729   \u001b[0m | \u001b[0m 1.641   \u001b[0m | \u001b[0m 0.8052  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.752132\ttraining's multi_logloss: 0.752132\tvalid_1's multi_logloss: 0.788485\tvalid_1's multi_logloss: 0.788485\n",
      "[200]\ttraining's multi_logloss: 0.69997\ttraining's multi_logloss: 0.69997\tvalid_1's multi_logloss: 0.768169\tvalid_1's multi_logloss: 0.768169\n",
      "[300]\ttraining's multi_logloss: 0.663694\ttraining's multi_logloss: 0.663694\tvalid_1's multi_logloss: 0.756633\tvalid_1's multi_logloss: 0.756633\n",
      "[400]\ttraining's multi_logloss: 0.63312\ttraining's multi_logloss: 0.63312\tvalid_1's multi_logloss: 0.747825\tvalid_1's multi_logloss: 0.747825\n",
      "[500]\ttraining's multi_logloss: 0.606898\ttraining's multi_logloss: 0.606898\tvalid_1's multi_logloss: 0.741483\tvalid_1's multi_logloss: 0.741483\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.606898\ttraining's multi_logloss: 0.606898\tvalid_1's multi_logloss: 0.741483\tvalid_1's multi_logloss: 0.741483\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.7091  \u001b[0m | \u001b[95m 0.9181  \u001b[0m | \u001b[95m 237.5   \u001b[0m | \u001b[95m 15.88   \u001b[0m | \u001b[95m 17.64   \u001b[0m | \u001b[95m 16.24   \u001b[0m | \u001b[95m 57.03   \u001b[0m | \u001b[95m 1.78    \u001b[0m | \u001b[95m 2.588   \u001b[0m | \u001b[95m 0.9085  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.754672\ttraining's multi_logloss: 0.754672\tvalid_1's multi_logloss: 0.790045\tvalid_1's multi_logloss: 0.790045\n",
      "[200]\ttraining's multi_logloss: 0.702008\ttraining's multi_logloss: 0.702008\tvalid_1's multi_logloss: 0.768166\tvalid_1's multi_logloss: 0.768166\n",
      "[300]\ttraining's multi_logloss: 0.666354\ttraining's multi_logloss: 0.666354\tvalid_1's multi_logloss: 0.756899\tvalid_1's multi_logloss: 0.756899\n",
      "[400]\ttraining's multi_logloss: 0.637646\ttraining's multi_logloss: 0.637646\tvalid_1's multi_logloss: 0.749008\tvalid_1's multi_logloss: 0.749008\n",
      "[500]\ttraining's multi_logloss: 0.613524\ttraining's multi_logloss: 0.613524\tvalid_1's multi_logloss: 0.74351\tvalid_1's multi_logloss: 0.74351\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.613524\ttraining's multi_logloss: 0.613524\tvalid_1's multi_logloss: 0.74351\tvalid_1's multi_logloss: 0.74351\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7091  \u001b[0m | \u001b[0m 0.8515  \u001b[0m | \u001b[0m 157.2   \u001b[0m | \u001b[0m 15.14   \u001b[0m | \u001b[0m 29.42   \u001b[0m | \u001b[0m 1.798   \u001b[0m | \u001b[0m 60.35   \u001b[0m | \u001b[0m 3.616   \u001b[0m | \u001b[0m 0.5277  \u001b[0m | \u001b[0m 0.9493  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.781367\ttraining's multi_logloss: 0.781367\tvalid_1's multi_logloss: 0.806841\tvalid_1's multi_logloss: 0.806841\n",
      "[200]\ttraining's multi_logloss: 0.735678\ttraining's multi_logloss: 0.735678\tvalid_1's multi_logloss: 0.784902\tvalid_1's multi_logloss: 0.784902\n",
      "[300]\ttraining's multi_logloss: 0.703718\ttraining's multi_logloss: 0.703718\tvalid_1's multi_logloss: 0.773669\tvalid_1's multi_logloss: 0.773669\n",
      "[400]\ttraining's multi_logloss: 0.677503\ttraining's multi_logloss: 0.677503\tvalid_1's multi_logloss: 0.764794\tvalid_1's multi_logloss: 0.764794\n",
      "[500]\ttraining's multi_logloss: 0.656492\ttraining's multi_logloss: 0.656492\tvalid_1's multi_logloss: 0.758609\tvalid_1's multi_logloss: 0.758609\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.656492\ttraining's multi_logloss: 0.656492\tvalid_1's multi_logloss: 0.758609\tvalid_1's multi_logloss: 0.758609\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7041  \u001b[0m | \u001b[0m 0.5388  \u001b[0m | \u001b[0m 173.6   \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 24.52   \u001b[0m | \u001b[0m 49.79   \u001b[0m | \u001b[0m 57.28   \u001b[0m | \u001b[0m 3.002   \u001b[0m | \u001b[0m 3.082   \u001b[0m | \u001b[0m 0.6342  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.757823\ttraining's multi_logloss: 0.757823\tvalid_1's multi_logloss: 0.79565\tvalid_1's multi_logloss: 0.79565\n",
      "[200]\ttraining's multi_logloss: 0.701152\ttraining's multi_logloss: 0.701152\tvalid_1's multi_logloss: 0.771456\tvalid_1's multi_logloss: 0.771456\n",
      "[300]\ttraining's multi_logloss: 0.662191\ttraining's multi_logloss: 0.662191\tvalid_1's multi_logloss: 0.758713\tvalid_1's multi_logloss: 0.758713\n",
      "[400]\ttraining's multi_logloss: 0.63148\ttraining's multi_logloss: 0.63148\tvalid_1's multi_logloss: 0.75028\tvalid_1's multi_logloss: 0.75028\n",
      "[500]\ttraining's multi_logloss: 0.606288\ttraining's multi_logloss: 0.606288\tvalid_1's multi_logloss: 0.744521\tvalid_1's multi_logloss: 0.744521\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.606288\ttraining's multi_logloss: 0.606288\tvalid_1's multi_logloss: 0.744521\tvalid_1's multi_logloss: 0.744521\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.7092  \u001b[0m | \u001b[95m 0.6061  \u001b[0m | \u001b[95m 334.3   \u001b[0m | \u001b[95m 15.97   \u001b[0m | \u001b[95m 20.67   \u001b[0m | \u001b[95m 15.01   \u001b[0m | \u001b[95m 62.82   \u001b[0m | \u001b[95m 1.801   \u001b[0m | \u001b[95m 4.06    \u001b[0m | \u001b[95m 0.5817  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.745964\ttraining's multi_logloss: 0.745964\tvalid_1's multi_logloss: 0.786014\tvalid_1's multi_logloss: 0.786014\n",
      "[200]\ttraining's multi_logloss: 0.693769\ttraining's multi_logloss: 0.693769\tvalid_1's multi_logloss: 0.766417\tvalid_1's multi_logloss: 0.766417\n",
      "[300]\ttraining's multi_logloss: 0.656303\ttraining's multi_logloss: 0.656303\tvalid_1's multi_logloss: 0.755972\tvalid_1's multi_logloss: 0.755972\n",
      "[400]\ttraining's multi_logloss: 0.624536\ttraining's multi_logloss: 0.624536\tvalid_1's multi_logloss: 0.747857\tvalid_1's multi_logloss: 0.747857\n",
      "[500]\ttraining's multi_logloss: 0.596866\ttraining's multi_logloss: 0.596866\tvalid_1's multi_logloss: 0.741223\tvalid_1's multi_logloss: 0.741223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.596866\ttraining's multi_logloss: 0.596866\tvalid_1's multi_logloss: 0.741223\tvalid_1's multi_logloss: 0.741223\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7087  \u001b[0m | \u001b[0m 0.9645  \u001b[0m | \u001b[0m 127.2   \u001b[0m | \u001b[0m 14.09   \u001b[0m | \u001b[0m 40.62   \u001b[0m | \u001b[0m 2.977   \u001b[0m | \u001b[0m 62.78   \u001b[0m | \u001b[0m 0.9191  \u001b[0m | \u001b[0m 3.924   \u001b[0m | \u001b[0m 0.9011  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.749994\ttraining's multi_logloss: 0.749994\tvalid_1's multi_logloss: 0.787765\tvalid_1's multi_logloss: 0.787765\n",
      "[200]\ttraining's multi_logloss: 0.697554\ttraining's multi_logloss: 0.697554\tvalid_1's multi_logloss: 0.766896\tvalid_1's multi_logloss: 0.766896\n",
      "[300]\ttraining's multi_logloss: 0.661012\ttraining's multi_logloss: 0.661012\tvalid_1's multi_logloss: 0.755393\tvalid_1's multi_logloss: 0.755393\n",
      "[400]\ttraining's multi_logloss: 0.631503\ttraining's multi_logloss: 0.631503\tvalid_1's multi_logloss: 0.747622\tvalid_1's multi_logloss: 0.747622\n",
      "[500]\ttraining's multi_logloss: 0.606012\ttraining's multi_logloss: 0.606012\tvalid_1's multi_logloss: 0.741923\tvalid_1's multi_logloss: 0.741923\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.606012\ttraining's multi_logloss: 0.606012\tvalid_1's multi_logloss: 0.741923\tvalid_1's multi_logloss: 0.741923\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.7095  \u001b[0m | \u001b[95m 0.9129  \u001b[0m | \u001b[95m 375.2   \u001b[0m | \u001b[95m 15.98   \u001b[0m | \u001b[95m 42.38   \u001b[0m | \u001b[95m 1.668   \u001b[0m | \u001b[95m 54.73   \u001b[0m | \u001b[95m 1.408   \u001b[0m | \u001b[95m 2.397   \u001b[0m | \u001b[95m 0.597   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.762963\ttraining's multi_logloss: 0.762963\tvalid_1's multi_logloss: 0.793877\tvalid_1's multi_logloss: 0.793877\n",
      "[200]\ttraining's multi_logloss: 0.715551\ttraining's multi_logloss: 0.715551\tvalid_1's multi_logloss: 0.774888\tvalid_1's multi_logloss: 0.774888\n",
      "[300]\ttraining's multi_logloss: 0.682156\ttraining's multi_logloss: 0.682156\tvalid_1's multi_logloss: 0.763798\tvalid_1's multi_logloss: 0.763798\n",
      "[400]\ttraining's multi_logloss: 0.656803\ttraining's multi_logloss: 0.656803\tvalid_1's multi_logloss: 0.756247\tvalid_1's multi_logloss: 0.756247\n",
      "[500]\ttraining's multi_logloss: 0.635462\ttraining's multi_logloss: 0.635462\tvalid_1's multi_logloss: 0.751211\tvalid_1's multi_logloss: 0.751211\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.635462\ttraining's multi_logloss: 0.635462\tvalid_1's multi_logloss: 0.751211\tvalid_1's multi_logloss: 0.751211\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7067  \u001b[0m | \u001b[0m 0.9952  \u001b[0m | \u001b[0m 223.7   \u001b[0m | \u001b[0m 15.47   \u001b[0m | \u001b[0m 13.07   \u001b[0m | \u001b[0m 11.12   \u001b[0m | \u001b[0m 59.92   \u001b[0m | \u001b[0m 6.156   \u001b[0m | \u001b[0m 1.109   \u001b[0m | \u001b[0m 0.5765  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.755454\ttraining's multi_logloss: 0.755454\tvalid_1's multi_logloss: 0.791115\tvalid_1's multi_logloss: 0.791115\n",
      "[200]\ttraining's multi_logloss: 0.707848\ttraining's multi_logloss: 0.707848\tvalid_1's multi_logloss: 0.773012\tvalid_1's multi_logloss: 0.773012\n",
      "[300]\ttraining's multi_logloss: 0.674545\ttraining's multi_logloss: 0.674545\tvalid_1's multi_logloss: 0.763599\tvalid_1's multi_logloss: 0.763599\n",
      "[400]\ttraining's multi_logloss: 0.649683\ttraining's multi_logloss: 0.649683\tvalid_1's multi_logloss: 0.756564\tvalid_1's multi_logloss: 0.756564\n",
      "[500]\ttraining's multi_logloss: 0.626577\ttraining's multi_logloss: 0.626577\tvalid_1's multi_logloss: 0.750712\tvalid_1's multi_logloss: 0.750712\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.626577\ttraining's multi_logloss: 0.626577\tvalid_1's multi_logloss: 0.750712\tvalid_1's multi_logloss: 0.750712\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7056  \u001b[0m | \u001b[0m 0.9569  \u001b[0m | \u001b[0m 217.4   \u001b[0m | \u001b[0m 15.3    \u001b[0m | \u001b[0m 115.2   \u001b[0m | \u001b[0m 2.463   \u001b[0m | \u001b[0m 59.93   \u001b[0m | \u001b[0m 1.05    \u001b[0m | \u001b[0m 5.203   \u001b[0m | \u001b[0m 0.8759  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.748178\ttraining's multi_logloss: 0.748178\tvalid_1's multi_logloss: 0.791087\tvalid_1's multi_logloss: 0.791087\n",
      "[200]\ttraining's multi_logloss: 0.689027\ttraining's multi_logloss: 0.689027\tvalid_1's multi_logloss: 0.76669\tvalid_1's multi_logloss: 0.76669\n",
      "[300]\ttraining's multi_logloss: 0.649232\ttraining's multi_logloss: 0.649232\tvalid_1's multi_logloss: 0.754692\tvalid_1's multi_logloss: 0.754692\n",
      "[400]\ttraining's multi_logloss: 0.617488\ttraining's multi_logloss: 0.617488\tvalid_1's multi_logloss: 0.746268\tvalid_1's multi_logloss: 0.746268\n",
      "[500]\ttraining's multi_logloss: 0.59028\ttraining's multi_logloss: 0.59028\tvalid_1's multi_logloss: 0.739845\tvalid_1's multi_logloss: 0.739845\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.59028\ttraining's multi_logloss: 0.59028\tvalid_1's multi_logloss: 0.739845\tvalid_1's multi_logloss: 0.739845\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 0.7106  \u001b[0m | \u001b[95m 0.6478  \u001b[0m | \u001b[95m 396.4   \u001b[0m | \u001b[95m 15.61   \u001b[0m | \u001b[95m 16.66   \u001b[0m | \u001b[95m 14.87   \u001b[0m | \u001b[95m 62.08   \u001b[0m | \u001b[95m 0.2835  \u001b[0m | \u001b[95m 1.498   \u001b[0m | \u001b[95m 0.9761  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.771194\ttraining's multi_logloss: 0.771194\tvalid_1's multi_logloss: 0.797528\tvalid_1's multi_logloss: 0.797528\n",
      "[200]\ttraining's multi_logloss: 0.725881\ttraining's multi_logloss: 0.725881\tvalid_1's multi_logloss: 0.777026\tvalid_1's multi_logloss: 0.777026\n",
      "[300]\ttraining's multi_logloss: 0.69642\ttraining's multi_logloss: 0.69642\tvalid_1's multi_logloss: 0.766514\tvalid_1's multi_logloss: 0.766514\n",
      "[400]\ttraining's multi_logloss: 0.67267\ttraining's multi_logloss: 0.67267\tvalid_1's multi_logloss: 0.759416\tvalid_1's multi_logloss: 0.759416\n",
      "[500]\ttraining's multi_logloss: 0.65173\ttraining's multi_logloss: 0.65173\tvalid_1's multi_logloss: 0.753397\tvalid_1's multi_logloss: 0.753397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.65173\ttraining's multi_logloss: 0.65173\tvalid_1's multi_logloss: 0.753397\tvalid_1's multi_logloss: 0.753397\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7055  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 166.0   \u001b[0m | \u001b[0m 15.86   \u001b[0m | \u001b[0m 14.13   \u001b[0m | \u001b[0m 3.059   \u001b[0m | \u001b[0m 49.5    \u001b[0m | \u001b[0m 3.454   \u001b[0m | \u001b[0m 9.725   \u001b[0m | \u001b[0m 0.8201  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.751688\ttraining's multi_logloss: 0.751688\tvalid_1's multi_logloss: 0.790924\tvalid_1's multi_logloss: 0.790924\n",
      "[200]\ttraining's multi_logloss: 0.696277\ttraining's multi_logloss: 0.696277\tvalid_1's multi_logloss: 0.767676\tvalid_1's multi_logloss: 0.767676\n",
      "[300]\ttraining's multi_logloss: 0.659049\ttraining's multi_logloss: 0.659049\tvalid_1's multi_logloss: 0.756515\tvalid_1's multi_logloss: 0.756515\n",
      "[400]\ttraining's multi_logloss: 0.62856\ttraining's multi_logloss: 0.62856\tvalid_1's multi_logloss: 0.748803\tvalid_1's multi_logloss: 0.748803\n",
      "[500]\ttraining's multi_logloss: 0.601438\ttraining's multi_logloss: 0.601438\tvalid_1's multi_logloss: 0.742455\tvalid_1's multi_logloss: 0.742455\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.601438\ttraining's multi_logloss: 0.601438\tvalid_1's multi_logloss: 0.742455\tvalid_1's multi_logloss: 0.742455\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7086  \u001b[0m | \u001b[0m 0.7112  \u001b[0m | \u001b[0m 249.4   \u001b[0m | \u001b[0m 15.94   \u001b[0m | \u001b[0m 19.05   \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 58.23   \u001b[0m | \u001b[0m 0.4221  \u001b[0m | \u001b[0m 3.375   \u001b[0m | \u001b[0m 0.932   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.762531\ttraining's multi_logloss: 0.762531\tvalid_1's multi_logloss: 0.794182\tvalid_1's multi_logloss: 0.794182\n",
      "[200]\ttraining's multi_logloss: 0.718176\ttraining's multi_logloss: 0.718176\tvalid_1's multi_logloss: 0.776129\tvalid_1's multi_logloss: 0.776129\n",
      "[300]\ttraining's multi_logloss: 0.689405\ttraining's multi_logloss: 0.689405\tvalid_1's multi_logloss: 0.766228\tvalid_1's multi_logloss: 0.766228\n",
      "[400]\ttraining's multi_logloss: 0.664962\ttraining's multi_logloss: 0.664962\tvalid_1's multi_logloss: 0.758926\tvalid_1's multi_logloss: 0.758926\n",
      "[500]\ttraining's multi_logloss: 0.642694\ttraining's multi_logloss: 0.642694\tvalid_1's multi_logloss: 0.752992\tvalid_1's multi_logloss: 0.752992\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.642694\ttraining's multi_logloss: 0.642694\tvalid_1's multi_logloss: 0.752992\tvalid_1's multi_logloss: 0.752992\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7047  \u001b[0m | \u001b[0m 0.844   \u001b[0m | \u001b[0m 141.0   \u001b[0m | \u001b[0m 9.812   \u001b[0m | \u001b[0m 22.1    \u001b[0m | \u001b[0m 19.73   \u001b[0m | \u001b[0m 54.71   \u001b[0m | \u001b[0m 1.526   \u001b[0m | \u001b[0m 4.63    \u001b[0m | \u001b[0m 0.7724  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.770159\ttraining's multi_logloss: 0.770159\tvalid_1's multi_logloss: 0.798279\tvalid_1's multi_logloss: 0.798279\n",
      "[200]\ttraining's multi_logloss: 0.724308\ttraining's multi_logloss: 0.724308\tvalid_1's multi_logloss: 0.776646\tvalid_1's multi_logloss: 0.776646\n",
      "[300]\ttraining's multi_logloss: 0.692237\ttraining's multi_logloss: 0.692237\tvalid_1's multi_logloss: 0.765034\tvalid_1's multi_logloss: 0.765034\n",
      "[400]\ttraining's multi_logloss: 0.666569\ttraining's multi_logloss: 0.666569\tvalid_1's multi_logloss: 0.757675\tvalid_1's multi_logloss: 0.757675\n",
      "[500]\ttraining's multi_logloss: 0.642502\ttraining's multi_logloss: 0.642502\tvalid_1's multi_logloss: 0.750785\tvalid_1's multi_logloss: 0.750785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.642502\ttraining's multi_logloss: 0.642502\tvalid_1's multi_logloss: 0.750785\tvalid_1's multi_logloss: 0.750785\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7051  \u001b[0m | \u001b[0m 0.6912  \u001b[0m | \u001b[0m 290.9   \u001b[0m | \u001b[0m 15.89   \u001b[0m | \u001b[0m 18.99   \u001b[0m | \u001b[0m 5.669   \u001b[0m | \u001b[0m 35.84   \u001b[0m | \u001b[0m 0.3138  \u001b[0m | \u001b[0m 0.1021  \u001b[0m | \u001b[0m 0.6399  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.749471\ttraining's multi_logloss: 0.749471\tvalid_1's multi_logloss: 0.788384\tvalid_1's multi_logloss: 0.788384\n",
      "[200]\ttraining's multi_logloss: 0.69788\ttraining's multi_logloss: 0.69788\tvalid_1's multi_logloss: 0.768455\tvalid_1's multi_logloss: 0.768455\n",
      "[300]\ttraining's multi_logloss: 0.662203\ttraining's multi_logloss: 0.662203\tvalid_1's multi_logloss: 0.757602\tvalid_1's multi_logloss: 0.757602\n",
      "[400]\ttraining's multi_logloss: 0.633391\ttraining's multi_logloss: 0.633391\tvalid_1's multi_logloss: 0.748892\tvalid_1's multi_logloss: 0.748892\n",
      "[500]\ttraining's multi_logloss: 0.608456\ttraining's multi_logloss: 0.608456\tvalid_1's multi_logloss: 0.742962\tvalid_1's multi_logloss: 0.742962\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.608456\ttraining's multi_logloss: 0.608456\tvalid_1's multi_logloss: 0.742962\tvalid_1's multi_logloss: 0.742962\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7086  \u001b[0m | \u001b[0m 0.9502  \u001b[0m | \u001b[0m 238.3   \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 11.23   \u001b[0m | \u001b[0m 24.5    \u001b[0m | \u001b[0m 58.76   \u001b[0m | \u001b[0m 0.4524  \u001b[0m | \u001b[0m 3.741   \u001b[0m | \u001b[0m 0.9392  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.746807\ttraining's multi_logloss: 0.746807\tvalid_1's multi_logloss: 0.788412\tvalid_1's multi_logloss: 0.788412\n",
      "[200]\ttraining's multi_logloss: 0.689949\ttraining's multi_logloss: 0.689949\tvalid_1's multi_logloss: 0.765445\tvalid_1's multi_logloss: 0.765445\n",
      "[300]\ttraining's multi_logloss: 0.651502\ttraining's multi_logloss: 0.651502\tvalid_1's multi_logloss: 0.75394\tvalid_1's multi_logloss: 0.75394\n",
      "[400]\ttraining's multi_logloss: 0.619824\ttraining's multi_logloss: 0.619824\tvalid_1's multi_logloss: 0.746136\tvalid_1's multi_logloss: 0.746136\n",
      "[500]\ttraining's multi_logloss: 0.592484\ttraining's multi_logloss: 0.592484\tvalid_1's multi_logloss: 0.739898\tvalid_1's multi_logloss: 0.739898\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.592484\ttraining's multi_logloss: 0.592484\tvalid_1's multi_logloss: 0.739898\tvalid_1's multi_logloss: 0.739898\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7087  \u001b[0m | \u001b[0m 0.7989  \u001b[0m | \u001b[0m 159.0   \u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 37.22   \u001b[0m | \u001b[0m 2.894   \u001b[0m | \u001b[0m 62.92   \u001b[0m | \u001b[0m 0.9692  \u001b[0m | \u001b[0m 2.6     \u001b[0m | \u001b[0m 0.6667  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.750833\ttraining's multi_logloss: 0.750833\tvalid_1's multi_logloss: 0.790788\tvalid_1's multi_logloss: 0.790788\n",
      "[200]\ttraining's multi_logloss: 0.695966\ttraining's multi_logloss: 0.695966\tvalid_1's multi_logloss: 0.76767\tvalid_1's multi_logloss: 0.76767\n",
      "[300]\ttraining's multi_logloss: 0.658244\ttraining's multi_logloss: 0.658244\tvalid_1's multi_logloss: 0.756448\tvalid_1's multi_logloss: 0.756448\n",
      "[400]\ttraining's multi_logloss: 0.628112\ttraining's multi_logloss: 0.628112\tvalid_1's multi_logloss: 0.748791\tvalid_1's multi_logloss: 0.748791\n",
      "[500]\ttraining's multi_logloss: 0.601914\ttraining's multi_logloss: 0.601914\tvalid_1's multi_logloss: 0.743028\tvalid_1's multi_logloss: 0.743028\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.601914\ttraining's multi_logloss: 0.601914\tvalid_1's multi_logloss: 0.743028\tvalid_1's multi_logloss: 0.743028\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.711   \u001b[0m | \u001b[95m 0.7675  \u001b[0m | \u001b[95m 269.6   \u001b[0m | \u001b[95m 13.9    \u001b[0m | \u001b[95m 68.27   \u001b[0m | \u001b[95m 9.013   \u001b[0m | \u001b[95m 63.39   \u001b[0m | \u001b[95m 1.764   \u001b[0m | \u001b[95m 0.6887  \u001b[0m | \u001b[95m 0.501   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.755282\ttraining's multi_logloss: 0.755282\tvalid_1's multi_logloss: 0.791997\tvalid_1's multi_logloss: 0.791997\n",
      "[200]\ttraining's multi_logloss: 0.706079\ttraining's multi_logloss: 0.706079\tvalid_1's multi_logloss: 0.772525\tvalid_1's multi_logloss: 0.772525\n",
      "[300]\ttraining's multi_logloss: 0.672815\ttraining's multi_logloss: 0.672815\tvalid_1's multi_logloss: 0.762101\tvalid_1's multi_logloss: 0.762101\n",
      "[400]\ttraining's multi_logloss: 0.646629\ttraining's multi_logloss: 0.646629\tvalid_1's multi_logloss: 0.754504\tvalid_1's multi_logloss: 0.754504\n",
      "[500]\ttraining's multi_logloss: 0.623722\ttraining's multi_logloss: 0.623722\tvalid_1's multi_logloss: 0.748688\tvalid_1's multi_logloss: 0.748688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.623722\ttraining's multi_logloss: 0.623722\tvalid_1's multi_logloss: 0.748688\tvalid_1's multi_logloss: 0.748688\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7076  \u001b[0m | \u001b[0m 0.9007  \u001b[0m | \u001b[0m 230.0   \u001b[0m | \u001b[0m 15.83   \u001b[0m | \u001b[0m 145.3   \u001b[0m | \u001b[0m 2.604   \u001b[0m | \u001b[0m 60.66   \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 0.1297  \u001b[0m | \u001b[0m 0.6202  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# BayesianOptimization객체를 수행할 함수와 search할 parameter 범위를 설정하여 생성. \n",
    "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=0)\n",
    "# 함수 반환값이 최대가 되는 입력값 유추를 위한 iteration 수행. \n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16lhW6ZSJjol"
   },
   "outputs": [],
   "source": [
    "# # BayesianOptimization객체의 res는 iteration 수행 시마다 모든 함수 반환결과와 그때의 파라미터 결과값을 가지고 있음. \n",
    "# lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1618386452664,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "61C1XY2hJoE6",
    "outputId": "0b9a75d2-acc0-417f-aec6-1829e37a9d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6945074326026707, 0.6977828168304359, 0.7024439405391786, 0.6945074326026707, 0.6951373141849332, 0.6962711010330058, 0.6951373141849332, 0.7026958931720837, 0.6957671957671958, 0.6948853615520282, 0.708994708994709, 0.7035777273872512, 0.7062232300327539, 0.7091206853111615, 0.7091206853111615, 0.7040816326530612, 0.709246661627614, 0.708742756361804, 0.709498614260519, 0.7067271352985639, 0.7055933484504913, 0.7106324011085916, 0.7054673721340388, 0.7086167800453514, 0.7047115142353237, 0.7050894431846813, 0.7086167800453514, 0.708742756361804, 0.7110103300579491, 0.7076089695137314]\n",
      "maximum target index: 28\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmax(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1618386458513,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "CwHuU8LkJxAP",
    "outputId": "b82abc4d-8388-4fba-eab9-0dec394ec327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.7110103300579491, 'params': {'colsample_bytree': 0.7674567512954314, 'max_bin': 269.6109200398602, 'max_depth': 13.896975914831401, 'min_child_samples': 68.26720342186422, 'min_child_weight': 9.013217831887559, 'num_leaves': 63.394654638730955, 'reg_alpha': 1.7639768328775685, 'reg_lambda': 0.688724140896305, 'subsample': 0.5009743194948411}}\n"
     ]
    }
   ],
   "source": [
    "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Onk3TMdaFPD5"
   },
   "source": [
    "#### 5-2 최적의 파라미터로 학습/예측 한번만 시행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vm8rjbrPJ5z5"
   },
   "outputs": [],
   "source": [
    "# 최적화된 하이퍼 파라미터를 기반으로 재 테스트\n",
    "def train_all(train):\n",
    "    ftr_train = train.drop(['index', 'credit'], axis=1)\n",
    "    target_train = train['credit']\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_train, target_train, test_size=0.3, random_state=2020)\n",
    "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
    "    clf = LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                max_depth = 14,\n",
    "                num_leaves=63,\n",
    "                colsample_bytree=0.767,\n",
    "                subsample=0.8,\n",
    "                max_bin=270,\n",
    "                reg_alpha=1.764,\n",
    "                reg_lambda=0.689,\n",
    "                min_child_weight=9,\n",
    "                min_child_samples=68,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1618387068844,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "zV3K5FMzeQKN",
    "outputId": "739176d8-7be0-4b14-8d5a-44d7ecd60ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 30), (10000, 29))"
      ]
     },
     "execution_count": 657,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data[~data['credit'].isnull()]\n",
    "test = data[data['credit'].isnull()]\n",
    "test = test.drop('credit', axis=1)\n",
    "train.shape , test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24522,
     "status": "ok",
     "timestamp": 1618387095359,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "e6I90N7ed0x8",
    "outputId": "f4318169-f357-4b97-b7d6-4519951b9b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (18519, 28) valid shape: (7938, 28)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.747335\ttraining's multi_logloss: 0.747335\tvalid_1's multi_logloss: 0.796219\tvalid_1's multi_logloss: 0.796219\n",
      "[200]\ttraining's multi_logloss: 0.69278\ttraining's multi_logloss: 0.69278\tvalid_1's multi_logloss: 0.774333\tvalid_1's multi_logloss: 0.774333\n",
      "[300]\ttraining's multi_logloss: 0.653517\ttraining's multi_logloss: 0.653517\tvalid_1's multi_logloss: 0.763178\tvalid_1's multi_logloss: 0.763178\n",
      "[400]\ttraining's multi_logloss: 0.62304\ttraining's multi_logloss: 0.62304\tvalid_1's multi_logloss: 0.756523\tvalid_1's multi_logloss: 0.756523\n",
      "[500]\ttraining's multi_logloss: 0.597562\ttraining's multi_logloss: 0.597562\tvalid_1's multi_logloss: 0.75112\tvalid_1's multi_logloss: 0.75112\n",
      "[600]\ttraining's multi_logloss: 0.574393\ttraining's multi_logloss: 0.574393\tvalid_1's multi_logloss: 0.746415\tvalid_1's multi_logloss: 0.746415\n",
      "[700]\ttraining's multi_logloss: 0.553762\ttraining's multi_logloss: 0.553762\tvalid_1's multi_logloss: 0.743361\tvalid_1's multi_logloss: 0.743361\n",
      "[800]\ttraining's multi_logloss: 0.535636\ttraining's multi_logloss: 0.535636\tvalid_1's multi_logloss: 0.741101\tvalid_1's multi_logloss: 0.741101\n",
      "[900]\ttraining's multi_logloss: 0.518494\ttraining's multi_logloss: 0.518494\tvalid_1's multi_logloss: 0.740053\tvalid_1's multi_logloss: 0.740053\n",
      "[1000]\ttraining's multi_logloss: 0.502668\ttraining's multi_logloss: 0.502668\tvalid_1's multi_logloss: 0.739151\tvalid_1's multi_logloss: 0.739151\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's multi_logloss: 0.502668\ttraining's multi_logloss: 0.502668\tvalid_1's multi_logloss: 0.739151\tvalid_1's multi_logloss: 0.739151\n"
     ]
    }
   ],
   "source": [
    "clf = train_all(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpmJSHRxCozY"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/content/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThfO2hoHCp4l"
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test.drop('index', axis=1))\n",
    "submission.iloc[:, 1:] = predictions\n",
    "submission.to_csv('submission_try02_tunning_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFveLon_Fm5z"
   },
   "source": [
    "#### 5-3. 최적의 파라미터로 OOF 검증하여 학습/예측 시행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsRPMfhHFj2H"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(train, test, nfolds=5):\n",
    "    ftr_train = train.drop(['index', 'credit'], axis=1)\n",
    "    target_train = train['credit']\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=2020)\n",
    "    \n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros((test.shape[0], 3))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMClassifier(\n",
    "                  nthread=4,\n",
    "                  n_estimators=4000,\n",
    "                  learning_rate=0.01,\n",
    "                  max_depth = 14,\n",
    "                  num_leaves=63,\n",
    "                  colsample_bytree=0.767,\n",
    "                  subsample=0.8,\n",
    "                  max_bin=270,\n",
    "                  reg_alpha=1.764,\n",
    "                  reg_lambda=0.689,\n",
    "                  min_child_weight=9,\n",
    "                  min_child_samples=68,\n",
    "                  silent=-1,\n",
    "                  verbose=-1,\n",
    "                  )\n",
    "\n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr_train)):\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x  = ftr_train.iloc[train_idx, :]\n",
    "        train_y = target_train.iloc[train_idx]\n",
    "        valid_x = ftr_train.iloc[valid_idx, :]\n",
    "        valid_y = target_train.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "   \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산. \n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict_proba(test.drop('index', axis=1), num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "        \n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414983,
     "status": "ok",
     "timestamp": 1618387753683,
     "user": {
      "displayName": "mana9017 Z",
      "photoUrl": "",
      "userId": "12890573916331922228"
     },
     "user_tz": -540
    },
    "id": "N1X-qktNFuEW",
    "outputId": "b7a0223b-2543-44ac-8af2-1c689846c0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration  0  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.748762\ttraining's multi_logloss: 0.748762\tvalid_1's multi_logloss: 0.802577\tvalid_1's multi_logloss: 0.802577\n",
      "[400]\ttraining's multi_logloss: 0.695694\ttraining's multi_logloss: 0.695694\tvalid_1's multi_logloss: 0.778688\tvalid_1's multi_logloss: 0.778688\n",
      "[600]\ttraining's multi_logloss: 0.660218\ttraining's multi_logloss: 0.660218\tvalid_1's multi_logloss: 0.766339\tvalid_1's multi_logloss: 0.766339\n",
      "[800]\ttraining's multi_logloss: 0.632211\ttraining's multi_logloss: 0.632211\tvalid_1's multi_logloss: 0.759286\tvalid_1's multi_logloss: 0.759286\n",
      "[1000]\ttraining's multi_logloss: 0.606614\ttraining's multi_logloss: 0.606614\tvalid_1's multi_logloss: 0.753165\tvalid_1's multi_logloss: 0.753165\n",
      "[1200]\ttraining's multi_logloss: 0.584055\ttraining's multi_logloss: 0.584055\tvalid_1's multi_logloss: 0.748449\tvalid_1's multi_logloss: 0.748449\n",
      "[1400]\ttraining's multi_logloss: 0.564274\ttraining's multi_logloss: 0.564274\tvalid_1's multi_logloss: 0.744676\tvalid_1's multi_logloss: 0.744676\n",
      "[1600]\ttraining's multi_logloss: 0.546805\ttraining's multi_logloss: 0.546805\tvalid_1's multi_logloss: 0.742236\tvalid_1's multi_logloss: 0.742236\n",
      "[1800]\ttraining's multi_logloss: 0.53035\ttraining's multi_logloss: 0.53035\tvalid_1's multi_logloss: 0.740568\tvalid_1's multi_logloss: 0.740568\n",
      "[2000]\ttraining's multi_logloss: 0.514927\ttraining's multi_logloss: 0.514927\tvalid_1's multi_logloss: 0.73924\tvalid_1's multi_logloss: 0.73924\n",
      "[2200]\ttraining's multi_logloss: 0.50103\ttraining's multi_logloss: 0.50103\tvalid_1's multi_logloss: 0.738459\tvalid_1's multi_logloss: 0.738459\n",
      "[2400]\ttraining's multi_logloss: 0.488264\ttraining's multi_logloss: 0.488264\tvalid_1's multi_logloss: 0.738163\tvalid_1's multi_logloss: 0.738163\n",
      "Early stopping, best iteration is:\n",
      "[2331]\ttraining's multi_logloss: 0.49247\ttraining's multi_logloss: 0.49247\tvalid_1's multi_logloss: 0.738119\tvalid_1's multi_logloss: 0.738119\n",
      "##### iteration  1  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.754945\ttraining's multi_logloss: 0.754945\tvalid_1's multi_logloss: 0.781662\tvalid_1's multi_logloss: 0.781662\n",
      "[400]\ttraining's multi_logloss: 0.70183\ttraining's multi_logloss: 0.70183\tvalid_1's multi_logloss: 0.756525\tvalid_1's multi_logloss: 0.756525\n",
      "[600]\ttraining's multi_logloss: 0.66716\ttraining's multi_logloss: 0.66716\tvalid_1's multi_logloss: 0.744419\tvalid_1's multi_logloss: 0.744419\n",
      "[800]\ttraining's multi_logloss: 0.637833\ttraining's multi_logloss: 0.637833\tvalid_1's multi_logloss: 0.735626\tvalid_1's multi_logloss: 0.735626\n",
      "[1000]\ttraining's multi_logloss: 0.613222\ttraining's multi_logloss: 0.613222\tvalid_1's multi_logloss: 0.72942\tvalid_1's multi_logloss: 0.72942\n",
      "[1200]\ttraining's multi_logloss: 0.590827\ttraining's multi_logloss: 0.590827\tvalid_1's multi_logloss: 0.724028\tvalid_1's multi_logloss: 0.724028\n",
      "[1400]\ttraining's multi_logloss: 0.571262\ttraining's multi_logloss: 0.571262\tvalid_1's multi_logloss: 0.720448\tvalid_1's multi_logloss: 0.720448\n",
      "[1600]\ttraining's multi_logloss: 0.553273\ttraining's multi_logloss: 0.553273\tvalid_1's multi_logloss: 0.717174\tvalid_1's multi_logloss: 0.717174\n",
      "[1800]\ttraining's multi_logloss: 0.536688\ttraining's multi_logloss: 0.536688\tvalid_1's multi_logloss: 0.714831\tvalid_1's multi_logloss: 0.714831\n",
      "[2000]\ttraining's multi_logloss: 0.521683\ttraining's multi_logloss: 0.521683\tvalid_1's multi_logloss: 0.713189\tvalid_1's multi_logloss: 0.713189\n",
      "[2200]\ttraining's multi_logloss: 0.507535\ttraining's multi_logloss: 0.507535\tvalid_1's multi_logloss: 0.711971\tvalid_1's multi_logloss: 0.711971\n",
      "[2400]\ttraining's multi_logloss: 0.494651\ttraining's multi_logloss: 0.494651\tvalid_1's multi_logloss: 0.711179\tvalid_1's multi_logloss: 0.711179\n",
      "[2600]\ttraining's multi_logloss: 0.482304\ttraining's multi_logloss: 0.482304\tvalid_1's multi_logloss: 0.710754\tvalid_1's multi_logloss: 0.710754\n",
      "[2800]\ttraining's multi_logloss: 0.470852\ttraining's multi_logloss: 0.470852\tvalid_1's multi_logloss: 0.710803\tvalid_1's multi_logloss: 0.710803\n",
      "Early stopping, best iteration is:\n",
      "[2690]\ttraining's multi_logloss: 0.477091\ttraining's multi_logloss: 0.477091\tvalid_1's multi_logloss: 0.71068\tvalid_1's multi_logloss: 0.71068\n",
      "##### iteration  2  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.752589\ttraining's multi_logloss: 0.752589\tvalid_1's multi_logloss: 0.786891\tvalid_1's multi_logloss: 0.786891\n",
      "[400]\ttraining's multi_logloss: 0.698499\ttraining's multi_logloss: 0.698499\tvalid_1's multi_logloss: 0.763035\tvalid_1's multi_logloss: 0.763035\n",
      "[600]\ttraining's multi_logloss: 0.661745\ttraining's multi_logloss: 0.661745\tvalid_1's multi_logloss: 0.751351\tvalid_1's multi_logloss: 0.751351\n",
      "[800]\ttraining's multi_logloss: 0.632626\ttraining's multi_logloss: 0.632626\tvalid_1's multi_logloss: 0.74448\tvalid_1's multi_logloss: 0.74448\n",
      "[1000]\ttraining's multi_logloss: 0.607649\ttraining's multi_logloss: 0.607649\tvalid_1's multi_logloss: 0.739707\tvalid_1's multi_logloss: 0.739707\n",
      "[1200]\ttraining's multi_logloss: 0.586489\ttraining's multi_logloss: 0.586489\tvalid_1's multi_logloss: 0.735913\tvalid_1's multi_logloss: 0.735913\n",
      "[1400]\ttraining's multi_logloss: 0.566863\ttraining's multi_logloss: 0.566863\tvalid_1's multi_logloss: 0.732665\tvalid_1's multi_logloss: 0.732665\n",
      "[1600]\ttraining's multi_logloss: 0.549485\ttraining's multi_logloss: 0.549485\tvalid_1's multi_logloss: 0.731444\tvalid_1's multi_logloss: 0.731444\n",
      "[1800]\ttraining's multi_logloss: 0.533062\ttraining's multi_logloss: 0.533062\tvalid_1's multi_logloss: 0.730889\tvalid_1's multi_logloss: 0.730889\n",
      "[2000]\ttraining's multi_logloss: 0.517463\ttraining's multi_logloss: 0.517463\tvalid_1's multi_logloss: 0.730051\tvalid_1's multi_logloss: 0.730051\n",
      "[2200]\ttraining's multi_logloss: 0.503141\ttraining's multi_logloss: 0.503141\tvalid_1's multi_logloss: 0.729641\tvalid_1's multi_logloss: 0.729641\n",
      "[2400]\ttraining's multi_logloss: 0.490044\ttraining's multi_logloss: 0.490044\tvalid_1's multi_logloss: 0.729561\tvalid_1's multi_logloss: 0.729561\n",
      "Early stopping, best iteration is:\n",
      "[2241]\ttraining's multi_logloss: 0.500377\ttraining's multi_logloss: 0.500377\tvalid_1's multi_logloss: 0.729497\tvalid_1's multi_logloss: 0.729497\n",
      "##### iteration  3  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.751601\ttraining's multi_logloss: 0.751601\tvalid_1's multi_logloss: 0.796195\tvalid_1's multi_logloss: 0.796195\n",
      "[400]\ttraining's multi_logloss: 0.699206\ttraining's multi_logloss: 0.699206\tvalid_1's multi_logloss: 0.773159\tvalid_1's multi_logloss: 0.773159\n",
      "[600]\ttraining's multi_logloss: 0.663006\ttraining's multi_logloss: 0.663006\tvalid_1's multi_logloss: 0.761388\tvalid_1's multi_logloss: 0.761388\n",
      "[800]\ttraining's multi_logloss: 0.634075\ttraining's multi_logloss: 0.634075\tvalid_1's multi_logloss: 0.752218\tvalid_1's multi_logloss: 0.752218\n",
      "[1000]\ttraining's multi_logloss: 0.609011\ttraining's multi_logloss: 0.609011\tvalid_1's multi_logloss: 0.744968\tvalid_1's multi_logloss: 0.744968\n",
      "[1200]\ttraining's multi_logloss: 0.587406\ttraining's multi_logloss: 0.587406\tvalid_1's multi_logloss: 0.738777\tvalid_1's multi_logloss: 0.738777\n",
      "[1400]\ttraining's multi_logloss: 0.568666\ttraining's multi_logloss: 0.568666\tvalid_1's multi_logloss: 0.734423\tvalid_1's multi_logloss: 0.734423\n",
      "[1600]\ttraining's multi_logloss: 0.551032\ttraining's multi_logloss: 0.551032\tvalid_1's multi_logloss: 0.730785\tvalid_1's multi_logloss: 0.730785\n",
      "[1800]\ttraining's multi_logloss: 0.534909\ttraining's multi_logloss: 0.534909\tvalid_1's multi_logloss: 0.728035\tvalid_1's multi_logloss: 0.728035\n",
      "[2000]\ttraining's multi_logloss: 0.519978\ttraining's multi_logloss: 0.519978\tvalid_1's multi_logloss: 0.725519\tvalid_1's multi_logloss: 0.725519\n",
      "[2200]\ttraining's multi_logloss: 0.505883\ttraining's multi_logloss: 0.505883\tvalid_1's multi_logloss: 0.723957\tvalid_1's multi_logloss: 0.723957\n",
      "[2400]\ttraining's multi_logloss: 0.492825\ttraining's multi_logloss: 0.492825\tvalid_1's multi_logloss: 0.723319\tvalid_1's multi_logloss: 0.723319\n",
      "[2600]\ttraining's multi_logloss: 0.480388\ttraining's multi_logloss: 0.480388\tvalid_1's multi_logloss: 0.722756\tvalid_1's multi_logloss: 0.722756\n",
      "[2800]\ttraining's multi_logloss: 0.468779\ttraining's multi_logloss: 0.468779\tvalid_1's multi_logloss: 0.722148\tvalid_1's multi_logloss: 0.722148\n",
      "[3000]\ttraining's multi_logloss: 0.457775\ttraining's multi_logloss: 0.457775\tvalid_1's multi_logloss: 0.722059\tvalid_1's multi_logloss: 0.722059\n",
      "[3200]\ttraining's multi_logloss: 0.44756\ttraining's multi_logloss: 0.44756\tvalid_1's multi_logloss: 0.721763\tvalid_1's multi_logloss: 0.721763\n",
      "[3400]\ttraining's multi_logloss: 0.437358\ttraining's multi_logloss: 0.437358\tvalid_1's multi_logloss: 0.721459\tvalid_1's multi_logloss: 0.721459\n",
      "[3600]\ttraining's multi_logloss: 0.42786\ttraining's multi_logloss: 0.42786\tvalid_1's multi_logloss: 0.721648\tvalid_1's multi_logloss: 0.721648\n",
      "Early stopping, best iteration is:\n",
      "[3463]\ttraining's multi_logloss: 0.434241\ttraining's multi_logloss: 0.434241\tvalid_1's multi_logloss: 0.721444\tvalid_1's multi_logloss: 0.721444\n",
      "##### iteration  4  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.752589\ttraining's multi_logloss: 0.752589\tvalid_1's multi_logloss: 0.790518\tvalid_1's multi_logloss: 0.790518\n",
      "[400]\ttraining's multi_logloss: 0.699374\ttraining's multi_logloss: 0.699374\tvalid_1's multi_logloss: 0.767878\tvalid_1's multi_logloss: 0.767878\n",
      "[600]\ttraining's multi_logloss: 0.663874\ttraining's multi_logloss: 0.663874\tvalid_1's multi_logloss: 0.756225\tvalid_1's multi_logloss: 0.756225\n",
      "[800]\ttraining's multi_logloss: 0.634793\ttraining's multi_logloss: 0.634793\tvalid_1's multi_logloss: 0.746737\tvalid_1's multi_logloss: 0.746737\n",
      "[1000]\ttraining's multi_logloss: 0.610504\ttraining's multi_logloss: 0.610504\tvalid_1's multi_logloss: 0.739942\tvalid_1's multi_logloss: 0.739942\n",
      "[1200]\ttraining's multi_logloss: 0.589366\ttraining's multi_logloss: 0.589366\tvalid_1's multi_logloss: 0.73487\tvalid_1's multi_logloss: 0.73487\n",
      "[1400]\ttraining's multi_logloss: 0.570447\ttraining's multi_logloss: 0.570447\tvalid_1's multi_logloss: 0.730612\tvalid_1's multi_logloss: 0.730612\n",
      "[1600]\ttraining's multi_logloss: 0.553107\ttraining's multi_logloss: 0.553107\tvalid_1's multi_logloss: 0.727287\tvalid_1's multi_logloss: 0.727287\n",
      "[1800]\ttraining's multi_logloss: 0.536988\ttraining's multi_logloss: 0.536988\tvalid_1's multi_logloss: 0.725162\tvalid_1's multi_logloss: 0.725162\n",
      "[2000]\ttraining's multi_logloss: 0.521913\ttraining's multi_logloss: 0.521913\tvalid_1's multi_logloss: 0.723037\tvalid_1's multi_logloss: 0.723037\n",
      "[2200]\ttraining's multi_logloss: 0.508047\ttraining's multi_logloss: 0.508047\tvalid_1's multi_logloss: 0.721876\tvalid_1's multi_logloss: 0.721876\n",
      "[2400]\ttraining's multi_logloss: 0.494873\ttraining's multi_logloss: 0.494873\tvalid_1's multi_logloss: 0.72057\tvalid_1's multi_logloss: 0.72057\n",
      "[2600]\ttraining's multi_logloss: 0.482836\ttraining's multi_logloss: 0.482836\tvalid_1's multi_logloss: 0.719885\tvalid_1's multi_logloss: 0.719885\n",
      "[2800]\ttraining's multi_logloss: 0.471438\ttraining's multi_logloss: 0.471438\tvalid_1's multi_logloss: 0.719545\tvalid_1's multi_logloss: 0.719545\n",
      "[3000]\ttraining's multi_logloss: 0.460811\ttraining's multi_logloss: 0.460811\tvalid_1's multi_logloss: 0.719968\tvalid_1's multi_logloss: 0.719968\n",
      "Early stopping, best iteration is:\n",
      "[2800]\ttraining's multi_logloss: 0.471438\ttraining's multi_logloss: 0.471438\tvalid_1's multi_logloss: 0.719545\tvalid_1's multi_logloss: 0.719545\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(train, test, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V17yhjo1F_lM"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/content/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvvrQIAxGAHK"
   },
   "outputs": [],
   "source": [
    "submission.iloc[:, 1:] = test_preds\n",
    "submission.to_csv('submission_try02_tunning_3_oof.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGLO8tIxnydf1z5p3Hhpr8",
   "collapsed_sections": [
    "bNuIcdXitE5d",
    "It6o1aN6r40g",
    "ixZxI8-Wsz11"
   ],
   "mount_file_id": "1ltGsNUoLJZNyA41QFqvfO7oBDYCu3lXt",
   "name": "Dacon_user_credit_prediction.ipynb",
   "provenance": [
    {
     "file_id": "1ltGsNUoLJZNyA41QFqvfO7oBDYCu3lXt",
     "timestamp": 1618388387648
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
