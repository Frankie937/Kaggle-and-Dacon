{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KofLsavcfCFI"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntts5788fGxD"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Dacon/data/train.csv\" \"/content/data/train.csv\"\n",
    "!cp \"/content/drive/MyDrive/Dacon/data/test.csv\" \"/content/data/test.csv\"\n",
    "!cp \"/content/drive/MyDrive/Dacon/data/sample_submission.csv\" \"/content/data/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUGMaKx-dAuM",
    "outputId": "4fed6016-6808-4b3d-9fee-68afdec7abbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11687 sha256=1a41924387b06881117abc054ade7e7615cefdf47b8e2f975202339eba79ce4f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.2.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XG_rtqPNdQfd"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/data/train.csv')\n",
    "test = pd.read_csv('/content/data/test.csv')\n",
    "submission = pd.read_csv('/content/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNuIcdXitE5d"
   },
   "source": [
    "### 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVgbndXddaBS",
    "outputId": "d440080f-82fe-4a66-a7a9-ebf04a95235d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26457, 20)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFbVQ16odoaU",
    "outputId": "65c6e1ac-c2e8-4cab-9f3e-790352c8749c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26457 entries, 0 to 26456\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   index          26457 non-null  int64  \n",
      " 1   gender         26457 non-null  object \n",
      " 2   car            26457 non-null  object \n",
      " 3   reality        26457 non-null  object \n",
      " 4   child_num      26457 non-null  int64  \n",
      " 5   income_total   26457 non-null  float64\n",
      " 6   income_type    26457 non-null  object \n",
      " 7   edu_type       26457 non-null  object \n",
      " 8   family_type    26457 non-null  object \n",
      " 9   house_type     26457 non-null  object \n",
      " 10  DAYS_BIRTH     26457 non-null  int64  \n",
      " 11  DAYS_EMPLOYED  26457 non-null  int64  \n",
      " 12  FLAG_MOBIL     26457 non-null  int64  \n",
      " 13  work_phone     26457 non-null  int64  \n",
      " 14  phone          26457 non-null  int64  \n",
      " 15  email          26457 non-null  int64  \n",
      " 16  occyp_type     18286 non-null  object \n",
      " 17  family_size    26457 non-null  float64\n",
      " 18  begin_month    26457 non-null  float64\n",
      " 19  credit         26457 non-null  float64\n",
      "dtypes: float64(4), int64(8), object(8)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTiEGqTyOBUO",
    "outputId": "c3ed3a0d-2d09-40c5-e306-3dd2c94172da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    16968\n",
       "1.0     6267\n",
       "0.0     3222\n",
       "Name: credit, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟값의 분포 확인\n",
    "train['credit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It6o1aN6r40g"
   },
   "source": [
    "### 2. 타겟값에 따라 continuous 피처의 분포도, categorical 피처의 분포도 확인 \n",
    "-> 주요 피처 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGS4p2jFsHd2",
    "outputId": "887812b7-6053-42f3-8270-73d6f91a3994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index            26457\n",
      "child_num            9\n",
      "income_total       249\n",
      "DAYS_BIRTH        6621\n",
      "DAYS_EMPLOYED     3470\n",
      "FLAG_MOBIL           1\n",
      "work_phone           2\n",
      "phone                2\n",
      "email                2\n",
      "family_size         10\n",
      "begin_month         61\n",
      "credit               3\n",
      "dtype: int64\n",
      "categorical feature ['FLAG_MOBIL', 'work_phone', 'phone', 'email', 'credit']\n",
      "continous feature ['income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month', 'child_num', 'family_size']\n"
     ]
    }
   ],
   "source": [
    "# numeric 피처 중에 categorical/continuous 피처 분리\n",
    "num_columns = train.dtypes[train.dtypes != 'object'].index.tolist()\n",
    "unique_len_num = train[num_columns].apply(lambda x : len(x.unique()))\n",
    "print(unique_len_num)\n",
    "# unique_len_num 보면서 분리 \n",
    "continuous = ['index','income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED','begin_month', 'child_num', 'family_size']\n",
    "ordinal = ['family_size', 'child_num'] # 혹시나 해서 ordinal 피처를 다시 분리 해놓기 \n",
    "categorical = [column for column in num_columns if column not in continuous]\n",
    "print('categorical feature', categorical)\n",
    "del continuous[0]\n",
    "print('continous feature', continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTB8L-jT6VD9"
   },
   "outputs": [],
   "source": [
    "def show_hist_by_target(df, columns):\n",
    "    cond_2 = (df['credit'] == 2)\n",
    "    cond_1 = (df['credit'] == 1)\n",
    "    cond_0 = (df['credit'] == 0)\n",
    "    \n",
    "    for column in columns:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4), squeeze=False)\n",
    "        sns.violinplot(x='credit', y=column, data=df, ax=axs[0][0] )\n",
    "        sns.distplot(df[cond_0][column], ax=axs[0][1], label='0', color='blue')\n",
    "        sns.distplot(df[cond_1][column], ax=axs[0][1], label='1', color='red')\n",
    "        sns.distplot(df[cond_2][column], ax=axs[0][1], label='2', color='green')\n",
    "\n",
    "show_hist_by_target(train, continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOTdxn6fuDKH",
    "outputId": "6d7eef72-4c84-4ad2-80d1-f82bfe4094cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical feature ['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'FLAG_MOBIL', 'work_phone', 'phone', 'email']\n"
     ]
    }
   ],
   "source": [
    "# object피처를 categorical 피처에 합치기\n",
    "object_columns = train.dtypes[train.dtypes == 'object'].index.tolist()\n",
    "categorical = object_columns + categorical\n",
    "del categorical[-1] # 'credit' 제거 \n",
    "print('categorical feature', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AC1IY5MyUfj"
   },
   "outputs": [],
   "source": [
    "# credit에 따라 categorical 피처들 분포 확인 \n",
    "def show_category_by_target(df, columns):\n",
    "    for column in columns:\n",
    "        chart = sns.catplot(x=column, col=\"credit\", data=df, kind=\"count\")\n",
    "        chart.set_xticklabels(rotation=65)\n",
    "        \n",
    "show_category_by_target(train, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kytjRMD5D0OV"
   },
   "outputs": [],
   "source": [
    "corr = train[continuous].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebW5ghnmOeDj"
   },
   "outputs": [],
   "source": [
    "#연속형 변수 분포 확인 \n",
    "sns.distplot(train['income_total']) # skew(오른쪽으로 긴 꼬리)\n",
    "sns.distplot(train['DAYS_BIRTH']) # 정규분포 형태 \n",
    "sns.distplot(train['DAYS_EMPLOYED']) # 양끝으로 두 분포 형태(이상치 의심)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UU-d-toqmU9"
   },
   "source": [
    "### 3. train과 test 데이터 합쳐서 피처엔지니어링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXOqQbeZgDa2"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnGApxXRtbn7"
   },
   "source": [
    "#### 3-0. 데이콘 강의_전처리 부분 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOIhCPCshQe0",
    "outputId": "40ddbdc3-54b3-4419-d4ec-92a6982c5fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BsX3S0elERF"
   },
   "outputs": [],
   "source": [
    "# 데이터의 모든 컬럼의 고유값의 개수를 확인  \n",
    "unique_len = data.apply(lambda x : len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MBFmeNelW42",
    "outputId": "6563d357-ace2-458b-dff2-883f5c9c41a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index            36457\n",
       "gender               2\n",
       "car                  2\n",
       "reality              2\n",
       "child_num            9\n",
       "income_total       265\n",
       "income_type          5\n",
       "edu_type             5\n",
       "family_type          5\n",
       "house_type           6\n",
       "DAYS_BIRTH        7183\n",
       "DAYS_EMPLOYED     3640\n",
       "FLAG_MOBIL           1\n",
       "work_phone           2\n",
       "phone                2\n",
       "email                2\n",
       "occyp_type          19\n",
       "family_size         10\n",
       "begin_month         61\n",
       "credit               4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw8VGnOhlYdj"
   },
   "outputs": [],
   "source": [
    "# 고유값 개수 2개 이하/ 2개 초과 10개 이하/ 10개 초과 그룹 3개로 나누기 \n",
    "group1 = unique_len[unique_len <= 2].index # binary \n",
    "group2 = unique_len[(unique_len > 2) & (unique_len <=10)].index # multi \n",
    "group3 = unique_len[unique_len > 10].index # contiunous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "6D-usiJhGQ74",
    "outputId": "877f5329-04f3-4c1f-f7ca-c6438b513133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  car  reality  FLAG_MOBIL  work_phone  phone  email\n",
       "0          0    0        0           1           0      0      0\n",
       "1          0    0        1           1           0      0      1\n",
       "2          1    1        1           1           0      1      0\n",
       "3          0    0        1           1           0      1      0\n",
       "4          0    1        1           1           0      0      0\n",
       "...      ...  ...      ...         ...         ...    ...    ...\n",
       "9995       0    1        1           1           1      1      0\n",
       "9996       1    1        1           1           1      0      0\n",
       "9997       0    0        1           1           0      0      0\n",
       "9998       0    1        0           1           0      1      0\n",
       "9999       0    0        1           1           0      0      1\n",
       "\n",
       "[36457 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <group1> 전처리 \n",
    "data[group1] # 확인 결과, gender, car, reality 문자열값을 0,1로 바꿔주기 \n",
    "data['gender'] = data['gender'].replace(['F', 'M'], [0,1])\n",
    "data['car'] = data['car'].replace(['N','Y'], [0,1])\n",
    "data['reality'] = data['reality'].replace(['N','Y'],[0,1])\n",
    "data[group1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "10M2a_5lLnTe",
    "outputId": "8a62f47a-d2eb-415c-be23-56345f46aa7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Incomplete higher</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      child_num           income_type  ... family_size credit\n",
       "0             0  Commercial associate  ...         2.0    1.0\n",
       "1             1  Commercial associate  ...         3.0    1.0\n",
       "2             0               Working  ...         2.0    2.0\n",
       "3             0  Commercial associate  ...         2.0    0.0\n",
       "4             0         State servant  ...         2.0    2.0\n",
       "...         ...                   ...  ...         ...    ...\n",
       "9995          0               Working  ...         2.0    NaN\n",
       "9996          0               Working  ...         2.0    NaN\n",
       "9997          0               Working  ...         2.0    NaN\n",
       "9998          0  Commercial associate  ...         2.0    NaN\n",
       "9999          0               Working  ...         2.0    NaN\n",
       "\n",
       "[36457 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <group2> 전처리\n",
    "data[group2] \n",
    "# child_num 는 따로 처리, 레이블인코딩-income_type, family_type, house_type, 매핑처리(ordinary)-edu_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwvEx0a9Ng7r"
   },
   "outputs": [],
   "source": [
    "# data['child_num'].value_counts().plot.bar()  #child_num의 분포를 보기 (value_counts()와 plot.bar() 이용 )\n",
    "# 3부터 19까지의 값은 거의 존재하지 않는 값이므로 이상치로 취급하고 2 초과인 값을 모두 2로 변경해주기 \n",
    "# sns.box_plot(data['child_num']) # child_num > 2.5 면 이상치로 나옴 \n",
    "data.loc[data['child_num'] > 2, 'child_num'] = 2\n",
    "# data['child_num'].value_counts().plot.bar() # 다시 분포 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1xW6T9SOX6x"
   },
   "outputs": [],
   "source": [
    "# sklearn.preprocessing의 LableEncoder 사용하여 income_type, family_type, house_type 처리 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8l8hhHuPmes"
   },
   "outputs": [],
   "source": [
    "data['income_type'] = label_encoder.fit_transform(data['income_type'])\n",
    "data['family_type'] = label_encoder.fit_transform(data['family_type'])\n",
    "data['house_type'] = label_encoder.fit_transform(data['house_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2IZOZgIOEua"
   },
   "outputs": [],
   "source": [
    "# ordinary 컬럼 edu_type 인코딩\n",
    "edu_order = {\n",
    "    'Lower secondary' : 0, # 중학교 미만\n",
    "    'Secondary / secondary special' : 1, #중학교\n",
    "    'Incomplete higher' : 2, # 고등학교 중퇴\n",
    "    'Higher education' : 3, # 고등학교 졸업\n",
    "     'Academic degree' : 4 # 학사 이상\n",
    "}\n",
    "data['edu_type'] = data['edu_type'].map(edu_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "veO_hA7EX1Ve",
    "outputId": "0bc8e306-f776-4878-de9f-fb609e9b5498"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>income_total</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>begin_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-13899</td>\n",
       "      <td>-4709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>-11380</td>\n",
       "      <td>-1540</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>-19087</td>\n",
       "      <td>-4434</td>\n",
       "      <td>Managers</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-15088</td>\n",
       "      <td>-2092</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>-15037</td>\n",
       "      <td>-2105</td>\n",
       "      <td>Managers</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-18593</td>\n",
       "      <td>-5434</td>\n",
       "      <td>Accountants</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-10886</td>\n",
       "      <td>-1315</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>292500.0</td>\n",
       "      <td>-21016</td>\n",
       "      <td>-14018</td>\n",
       "      <td>Medicine staff</td>\n",
       "      <td>-55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-16541</td>\n",
       "      <td>-1085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>-9154</td>\n",
       "      <td>-187</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36457 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  income_total  ...      occyp_type  begin_month\n",
       "0         0      202500.0  ...             NaN         -6.0\n",
       "1         1      247500.0  ...        Laborers         -5.0\n",
       "2         2      450000.0  ...        Managers        -22.0\n",
       "3         3      202500.0  ...     Sales staff        -37.0\n",
       "4         4      157500.0  ...        Managers        -26.0\n",
       "...     ...           ...  ...             ...          ...\n",
       "9995  36452      202500.0  ...     Accountants        -19.0\n",
       "9996  36453      202500.0  ...        Laborers        -34.0\n",
       "9997  36454      292500.0  ...  Medicine staff        -55.0\n",
       "9998  36455      180000.0  ...             NaN        -33.0\n",
       "9999  36456      270000.0  ...        Laborers        -11.0\n",
       "\n",
       "[36457 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[group3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFMsAQAMW11F"
   },
   "outputs": [],
   "source": [
    "# <group3> 이상치 평균값으로 대체, 구간화 변수들 새로 생성(피처새로 생성), occyp_type 피처 삭제 \n",
    "# 연속형 변수의 구간화 변수 새로 생성 (연속형 변수를 그대로 넣지 않고 구간화해서 모델에 넣을 경우 더 좋은 성능을 나타내는 알고리즘 모델이 있음)\n",
    "counts, bin_dividers = np.histogram(data['income_total'], bins = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcxsLopnYaaN"
   },
   "outputs": [],
   "source": [
    "pd.cut(data['income_total'], bins=bin_dividers, labels=np.arange(7), include_lowest=True)  # include_lowest=True 는 최솟값도 구간에 포함시키기 위해서 하는 것\n",
    "# pd.cut()의 반환 자료형은 'category'이다.(Series와는 다름) 'int'로 바꿔주기 위해 pd.factorize() 사용하기 \n",
    "pd.factorize(pd.cut(data['income_total'], bins=bin_dividers, labels=[i for i in range(7)], include_lowest=True))\n",
    "data['income_total_bin'] = pd.factorize(pd.cut(data['income_total'], bins=bin_dividers, include_lowest=True, labels=[i for i in range(7)]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KGxj4PbDarz",
    "outputId": "70f2dea2-8a32-416b-c5ea-2cbb72a37382"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 365243    6135\n",
       "-401         78\n",
       "-1539        64\n",
       "-200         63\n",
       "-2087        61\n",
       "           ... \n",
       "-3640         1\n",
       "-5717         1\n",
       "-4420         1\n",
       "-2203         1\n",
       "-2024         1\n",
       "Name: DAYS_EMPLOYED, Length: 3640, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DAYS_EMPLOYED'].value_counts()\n",
    "# DAYS_EMPLOYED의 값에서 365243 값이 이상함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEbZxN8tEE1T"
   },
   "outputs": [],
   "source": [
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].replace(365243, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrpBO-AzDumC"
   },
   "outputs": [],
   "source": [
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].fillna(data['DAYS_EMPLOYED'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8WDrgpUYQP5"
   },
   "outputs": [],
   "source": [
    "# 연속형 변수를 구간화하는 함수 만들고, 함수 이용하여 구간화 변수 3개 생성  \n",
    "def make_bin(array, n):\n",
    "    array = -array # DAYS_BIRTH, DAYS_EMPLOYED, begin_month 가 마이너스라서 \n",
    "    _, bin_dividers = np.histogram(array, bins=n)\n",
    "    categories = pd.cut(array, bins=bin_dividers, include_lowest=True, labels=[i for i in range(n)])\n",
    "    bined_array = pd.factorize(categories)[0]\n",
    "    return bined_array\n",
    "\n",
    "data['DAYS_BIRTH_BIN'] = make_bin(data['DAYS_BIRTH'], 10)\n",
    "data['DAYS_EMPLOYED_BIN'] = make_bin(data['DAYS_EMPLOYED'], 6)\n",
    "data['begin_month_bin'] = make_bin(data['begin_month'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0j4C18dC3No"
   },
   "outputs": [],
   "source": [
    "data.drop('occyp_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixZxI8-Wsz11"
   },
   "source": [
    "#### 3-1. object 피처들 레이블 인코딩(3-0 하면 안해도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu_d6z0qQiGh"
   },
   "outputs": [],
   "source": [
    "# data['edu_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wVrRqBpP8sq"
   },
   "outputs": [],
   "source": [
    "# # ordinary 한 피처 'edu_type'은 레이블 인코딩 말고 map으로 인코딩 \n",
    "# edu_order = {\n",
    "#     'Lower secondary' : 0, # 중학교 미만\n",
    "#     'Secondary / secondary special' : 1, #중학교\n",
    "#     'Incomplete higher' : 2, # 고등학교 중퇴\n",
    "#     'Higher education' : 3, # 고등학교 졸업\n",
    "#      'Academic degree' : 4 # 학사 이상\n",
    "# }\n",
    "# data.edu_type = data.edu_type.map(edu_order)\n",
    "# data['edu_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKamwdoBl6o3"
   },
   "outputs": [],
   "source": [
    "# object_columns = data.dtypes[data.dtypes=='object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQUAOLyaqR6z"
   },
   "outputs": [],
   "source": [
    "# for column in object_columns:\n",
    "#   data[column] = pd.factorize(data[column])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nIvPy4LFGoB"
   },
   "source": [
    "#### 3-2. 주요 피처 엔지니어링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFiyETQ4TBGW"
   },
   "source": [
    "##### 3-2-1. 전처리 함수화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxmARZAgP_FE"
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_df(data):\n",
    "    # 이진값 인코딩_group1 \n",
    "    data['gender'] = data['gender'].replace(['F', 'M'], [0,1])\n",
    "    data['car'] = data['car'].replace(['N','Y'], [0,1])\n",
    "    data['reality'] = data['reality'].replace(['N','Y'],[0,1])\n",
    "    # 레이블 인코딩_group2\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['income_type'] = label_encoder.fit_transform(data['income_type'])\n",
    "    data['family_type'] = label_encoder.fit_transform(data['family_type'])\n",
    "    data['house_type'] = label_encoder.fit_transform(data['house_type'])\n",
    "\n",
    "    # ordinary 컬럼 edu_type 인코딩\n",
    "    edu_order = {\n",
    "        'Lower secondary' : 0, # 중학교 미만\n",
    "        'Secondary / secondary special' : 1, #중학교\n",
    "        'Incomplete higher' : 2, # 고등학교 중퇴\n",
    "        'Higher education' : 3, # 고등학교 졸업\n",
    "        'Academic degree' : 4 # 학사 이상\n",
    "            }\n",
    "      data['edu_type'] = data['edu_type'].map(edu_order)\n",
    "\n",
    "    # 이상치 인코딩 \n",
    "    data.loc[data['child_num'] > 2, 'child_num'] = 2\n",
    "    data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].replace(365243, np.nan)\n",
    "    data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].fillna(data['DAYS_EMPLOYED'].mean())\n",
    "    # 결측치 많은 컬럼 제거 \n",
    "    data.drop('occyp_type', axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = get_preprocessed_df(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63FQV5XbTHiR"
   },
   "source": [
    "##### 3-2-2. 피처 가공(새로 생성) 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJzQKmPcFZG1"
   },
   "outputs": [],
   "source": [
    "# # baseline은 피처 가공 없이 한 것 \n",
    "# # submission_try01 피처가공 함수\n",
    "# def get_try01 (data):\n",
    "#   #  DAYS_BIRTH, DAYS_EMPLOYED 비율로 소득 Feature 가공. \n",
    "#   data['EMPLOYED_BIRTH_RATIO'] = data['DAYS_EMPLOYED']/data['DAYS_BIRTH']\n",
    "#   data['INCOME_EMPLOYED_RATIO'] = data['income_total']/data['DAYS_EMPLOYED']\n",
    "#   data['INCOME_BIRTH_RATIO'] = data['income_total']/data['DAYS_BIRTH']\n",
    "#   # 가족수를 고려한 가처분 소득 피처 가공. \n",
    "#   data['CNT_CHILD_INCOME_RATIO'] = data['income_total']/data['child_num']\n",
    "#   data['CNT_FAM_INCOME_RATIO'] = data['income_total']/data['family_size']\n",
    "#   return data \n",
    "\n",
    "# # try_01_valid = 0.7368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNAlM1uwBRCQ"
   },
   "outputs": [],
   "source": [
    "# submission_try02 피처가공 함수\n",
    "def get_try02 (data):\n",
    "    # 연속형 변수 구간화 변수 생성 \n",
    "    counts, bin_dividers = np.histogram(data['income_total'], bins = 7)\n",
    "    data['income_total_bin'] = pd.factorize(pd.cut(data['income_total'], bins=bin_dividers, include_lowest=True, labels=[i for i in range(7)]))[0]\n",
    "    # 연속형 변수를 구간화하는 함수 만들고, 함수 이용하여 구간화 변수 3개 생성  \n",
    "    def make_bin(array, n):\n",
    "        array = -array # DAYS_BIRTH, DAYS_EMPLOYED, begin_month 가 마이너스라서 \n",
    "        _, bin_dividers = np.histogram(array, bins=n)\n",
    "        categories = pd.cut(array, bins=bin_dividers, include_lowest=True, labels=[i for i in range(n)])\n",
    "        bined_array = pd.factorize(categories)[0]\n",
    "        return bined_array\n",
    "    data['DAYS_BIRTH_BIN'] = make_bin(data['DAYS_BIRTH'], 10)\n",
    "    data['DAYS_EMPLOYED_BIN'] = make_bin(data['DAYS_EMPLOYED'], 6)\n",
    "    data['begin_month_bin'] = make_bin(data['begin_month'], 4)\n",
    "\n",
    "    #  DAYS_BIRTH, DAYS_EMPLOYED 비율로 소득 Feature 가공. \n",
    "    data['EMPLOYED_BIRTH_RATIO'] = data['DAYS_EMPLOYED']/data['DAYS_BIRTH']\n",
    "    data['INCOME_EMPLOYED_RATIO'] = data['income_total']/data['DAYS_EMPLOYED']\n",
    "    data['INCOME_BIRTH_RATIO'] = data['income_total']/data['DAYS_BIRTH']\n",
    "    # 가족수와 자녀수 mean, sum 피처 가공\n",
    "    # data['FAM_CHILD_MEAN'] = data[['child_num', 'family_size']].mean(axis=1)\n",
    "    data['FAM_CHILD_SUM'] = data[['child_num', 'family_size']].sum(axis=1)\n",
    "    # 가족수를 고려한 가처분 소득 피처 가공. \n",
    "    # data['CNT_CHILD_INCOME_RATIO'] = data['income_total']/data['child_num']\n",
    "    data['CNT_FAM_INCOME_RATIO'] = data['income_total']/data['family_size']\n",
    "    # 소유 여부(0/1의 2개 category피처들)와 교육수준 관련 피처들 mean, sum 피처 가공 \n",
    "    data['HAVE_OR_NOT_MEAN'] =data[['car','reality','work_phone','phone','email','edu_type']].mean(axis=1)\n",
    "    #data['HAVE_OR_NOT_SUM'] =data[['car','reality','work_phone','phone','email', 'edu_type']].sum(axis=1)\n",
    "\n",
    "    # 고민해서 새로 추가(4/14) tunning_3버전\n",
    "    data['INCOME_HAVE_OR_NOT_RATIO'] = data['income_total']/data['HAVE_OR_NOT_MEAN']\n",
    "    # data['DAYS_SUM'] = data[['DAYS_BIRTH_BIN', 'DAYS_EMPLOYED_BIN', 'begin_month']].sum(axis=1)\n",
    "    # data['INCOME_DAYS_SUM_RATIO'] = data['income_total'] / data[['DAYS_BIRTH_BIN', 'DAYS_EMPLOYED_BIN', 'begin_month']].sum(axis=1)\n",
    "\n",
    "    # 로그변환한 income_total새로 추가(skew 되어 있어서)(4/17) tunning_5버전\n",
    "    data['income_total_log'] = np.log1p(data['income_total']) \n",
    "\n",
    "    return data  \n",
    "\n",
    "#try_02_valid = 0.7347\n",
    "data = get_try02(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8-eEm3sRDao"
   },
   "source": [
    "### 4. train-test 분리하고 학습/feature_importance 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ap_brJaARJ4L",
    "outputId": "cd8dc1f2-3c02-4627-f03d-d49617ed115e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 30), (10000, 29))"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data[~data['credit'].isnull()]\n",
    "test = data[data['credit'].isnull()]\n",
    "test = test.drop('credit', axis=1)\n",
    "train.shape , test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUmQme94SJII",
    "outputId": "5a670988-9717-4967-9f85-4a8b54d44cd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18519, 28), (7938, 28))"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습데이터를 다시 학습-검증데이터로 분리 (for 교차검증)\n",
    "ftr_train = train.drop(['index','credit'], axis=1)\n",
    "target_train = train['credit']\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr_train, target_train, test_size=0.3, random_state=156, stratify=target_train)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXzgSQtSJaUO"
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators= 1000, max_depth = 12, max_features=20 )\n",
    "# clf.fit(train_x, train_y)\n",
    "# predictions = clf.predict_proba(valid_x)\n",
    "# valid_y_onehot = pd.get_dummies(valid_y)\n",
    "# logloss = log_loss(valid_y_onehot, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oBprd3lTOvT",
    "outputId": "e8f83d70-af75-4532-9159-d9edf1cb7797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.769256\ttraining's multi_logloss: 0.769256\tvalid_1's multi_logloss: 0.79146\tvalid_1's multi_logloss: 0.79146\n",
      "[200]\ttraining's multi_logloss: 0.729411\ttraining's multi_logloss: 0.729411\tvalid_1's multi_logloss: 0.774213\tvalid_1's multi_logloss: 0.774213\n",
      "[300]\ttraining's multi_logloss: 0.699434\ttraining's multi_logloss: 0.699434\tvalid_1's multi_logloss: 0.765404\tvalid_1's multi_logloss: 0.765404\n",
      "[400]\ttraining's multi_logloss: 0.674527\ttraining's multi_logloss: 0.674527\tvalid_1's multi_logloss: 0.758241\tvalid_1's multi_logloss: 0.758241\n",
      "[500]\ttraining's multi_logloss: 0.652422\ttraining's multi_logloss: 0.652422\tvalid_1's multi_logloss: 0.7524\tvalid_1's multi_logloss: 0.7524\n",
      "[600]\ttraining's multi_logloss: 0.632413\ttraining's multi_logloss: 0.632413\tvalid_1's multi_logloss: 0.747505\tvalid_1's multi_logloss: 0.747505\n",
      "[700]\ttraining's multi_logloss: 0.613142\ttraining's multi_logloss: 0.613142\tvalid_1's multi_logloss: 0.743052\tvalid_1's multi_logloss: 0.743052\n",
      "[800]\ttraining's multi_logloss: 0.595864\ttraining's multi_logloss: 0.595864\tvalid_1's multi_logloss: 0.73987\tvalid_1's multi_logloss: 0.73987\n",
      "[900]\ttraining's multi_logloss: 0.579605\ttraining's multi_logloss: 0.579605\tvalid_1's multi_logloss: 0.737072\tvalid_1's multi_logloss: 0.737072\n",
      "[1000]\ttraining's multi_logloss: 0.564432\ttraining's multi_logloss: 0.564432\tvalid_1's multi_logloss: 0.734357\tvalid_1's multi_logloss: 0.734357\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's multi_logloss: 0.564432\ttraining's multi_logloss: 0.564432\tvalid_1's multi_logloss: 0.734357\tvalid_1's multi_logloss: 0.734357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.02, max_depth=12,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=1000, n_jobs=-1, num_leaves=32, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=-1,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0,\n",
       "               verbose=-1)"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LGBMClassifier 학습\n",
    "clf = LGBMClassifier(\n",
    "        n_jobs=-1,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=32,\n",
    "        subsample=0.8,\n",
    "        max_depth=12,\n",
    "        silent=-1,\n",
    "        verbose=-1\n",
    "        )\n",
    "clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "        early_stopping_rounds= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "FVCeqWZyVOrr",
    "outputId": "a8ecfdad-15a4-4680-8c88-7026d7d9a299"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff6f67c3890>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "plot_importance(clf, figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtI2A1-EBcuO"
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test.drop('index', axis=1))\n",
    "submission.iloc[:, 1:] = predictions \n",
    "submission.to_csv('submission_try02_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0o6nFh3TlEJ"
   },
   "source": [
    "### 5. 하이퍼파라미터 튜닝 후 학습/검증/예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cFnm2I-CO3P"
   },
   "source": [
    "#### 5-1 Bayesian Optimization 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBaLJ1q-VFz_"
   },
   "outputs": [],
   "source": [
    "# 베이지안 옵티마이저 사용하여 하이퍼파라미터 튜닝 \n",
    "bayesian_params = {\n",
    "    'max_depth': (6, 16), \n",
    "    'num_leaves': (8, 64), \n",
    "    'min_child_samples': (10, 200), \n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha': (0.01, 50) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-JLEfUAJCiT"
   },
   "outputs": [],
   "source": [
    "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
    "    params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
    "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': int(round(num_leaves)), \n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample': max(min(subsample, 1), 0), \n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'max_bin':  max(int(round(max_bin)),10),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_proba = lgb_model.predict(valid_x)\n",
    "    f1score = f1_score(valid_y, valid_proba, average='macro')\n",
    "    #accuracy = accuracy_score(valid_y, valid_proba)\n",
    "    #return accuracy\n",
    "\n",
    "    return f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOhEXnk7JhOd",
    "outputId": "538cb008-f920-452a-f4f1-bf6b1f26003b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.811728\ttraining's multi_logloss: 0.811728\tvalid_1's multi_logloss: 0.81357\tvalid_1's multi_logloss: 0.81357\n",
      "[200]\ttraining's multi_logloss: 0.789614\ttraining's multi_logloss: 0.789614\tvalid_1's multi_logloss: 0.798842\tvalid_1's multi_logloss: 0.798842\n",
      "[300]\ttraining's multi_logloss: 0.775987\ttraining's multi_logloss: 0.775987\tvalid_1's multi_logloss: 0.792327\tvalid_1's multi_logloss: 0.792327\n",
      "[400]\ttraining's multi_logloss: 0.765342\ttraining's multi_logloss: 0.765342\tvalid_1's multi_logloss: 0.788105\tvalid_1's multi_logloss: 0.788105\n",
      "[500]\ttraining's multi_logloss: 0.756828\ttraining's multi_logloss: 0.756828\tvalid_1's multi_logloss: 0.784779\tvalid_1's multi_logloss: 0.784779\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.756828\ttraining's multi_logloss: 0.756828\tvalid_1's multi_logloss: 0.784779\tvalid_1's multi_logloss: 0.784779\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3931  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 44.17   \u001b[0m | \u001b[0m 21.88   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.810277\ttraining's multi_logloss: 0.810277\tvalid_1's multi_logloss: 0.812286\tvalid_1's multi_logloss: 0.812286\n",
      "[200]\ttraining's multi_logloss: 0.789439\ttraining's multi_logloss: 0.789439\tvalid_1's multi_logloss: 0.797465\tvalid_1's multi_logloss: 0.797465\n",
      "[300]\ttraining's multi_logloss: 0.777244\ttraining's multi_logloss: 0.777244\tvalid_1's multi_logloss: 0.791153\tvalid_1's multi_logloss: 0.791153\n",
      "[400]\ttraining's multi_logloss: 0.767332\ttraining's multi_logloss: 0.767332\tvalid_1's multi_logloss: 0.787433\tvalid_1's multi_logloss: 0.787433\n",
      "[500]\ttraining's multi_logloss: 0.758331\ttraining's multi_logloss: 0.758331\tvalid_1's multi_logloss: 0.7841\tvalid_1's multi_logloss: 0.7841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.758331\ttraining's multi_logloss: 0.758331\tvalid_1's multi_logloss: 0.7841\tvalid_1's multi_logloss: 0.7841\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.3944  \u001b[0m | \u001b[95m 0.6917  \u001b[0m | \u001b[95m 397.9   \u001b[0m | \u001b[95m 11.29   \u001b[0m | \u001b[95m 117.9   \u001b[0m | \u001b[95m 46.35   \u001b[0m | \u001b[95m 11.98   \u001b[0m | \u001b[95m 4.366   \u001b[0m | \u001b[95m 0.2032  \u001b[0m | \u001b[95m 0.9163  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.777716\ttraining's multi_logloss: 0.777716\tvalid_1's multi_logloss: 0.796904\tvalid_1's multi_logloss: 0.796904\n",
      "[200]\ttraining's multi_logloss: 0.737338\ttraining's multi_logloss: 0.737338\tvalid_1's multi_logloss: 0.778094\tvalid_1's multi_logloss: 0.778094\n",
      "[300]\ttraining's multi_logloss: 0.707383\ttraining's multi_logloss: 0.707383\tvalid_1's multi_logloss: 0.767309\tvalid_1's multi_logloss: 0.767309\n",
      "[400]\ttraining's multi_logloss: 0.68285\ttraining's multi_logloss: 0.68285\tvalid_1's multi_logloss: 0.759751\tvalid_1's multi_logloss: 0.759751\n",
      "[500]\ttraining's multi_logloss: 0.663802\ttraining's multi_logloss: 0.663802\tvalid_1's multi_logloss: 0.75466\tvalid_1's multi_logloss: 0.75466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.663802\ttraining's multi_logloss: 0.663802\tvalid_1's multi_logloss: 0.75466\tvalid_1's multi_logloss: 0.75466\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.4255  \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 15.79   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 51.71   \u001b[0m | \u001b[95m 5.923   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.810315\ttraining's multi_logloss: 0.810315\tvalid_1's multi_logloss: 0.810461\tvalid_1's multi_logloss: 0.810461\n",
      "[200]\ttraining's multi_logloss: 0.79297\ttraining's multi_logloss: 0.79297\tvalid_1's multi_logloss: 0.79899\tvalid_1's multi_logloss: 0.79899\n",
      "[300]\ttraining's multi_logloss: 0.783176\ttraining's multi_logloss: 0.783176\tvalid_1's multi_logloss: 0.794324\tvalid_1's multi_logloss: 0.794324\n",
      "[400]\ttraining's multi_logloss: 0.777473\ttraining's multi_logloss: 0.777473\tvalid_1's multi_logloss: 0.791728\tvalid_1's multi_logloss: 0.791728\n",
      "[500]\ttraining's multi_logloss: 0.775193\ttraining's multi_logloss: 0.775193\tvalid_1's multi_logloss: 0.790752\tvalid_1's multi_logloss: 0.790752\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.775193\ttraining's multi_logloss: 0.775193\tvalid_1's multi_logloss: 0.790752\tvalid_1's multi_logloss: 0.790752\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.394   \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 33.54   \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.817137\ttraining's multi_logloss: 0.817137\tvalid_1's multi_logloss: 0.814982\tvalid_1's multi_logloss: 0.814982\n",
      "[200]\ttraining's multi_logloss: 0.802307\ttraining's multi_logloss: 0.802307\tvalid_1's multi_logloss: 0.802976\tvalid_1's multi_logloss: 0.802976\n",
      "[300]\ttraining's multi_logloss: 0.794728\ttraining's multi_logloss: 0.794728\tvalid_1's multi_logloss: 0.798647\tvalid_1's multi_logloss: 0.798647\n",
      "[400]\ttraining's multi_logloss: 0.790492\ttraining's multi_logloss: 0.790492\tvalid_1's multi_logloss: 0.796593\tvalid_1's multi_logloss: 0.796593\n",
      "[500]\ttraining's multi_logloss: 0.788505\ttraining's multi_logloss: 0.788505\tvalid_1's multi_logloss: 0.795687\tvalid_1's multi_logloss: 0.795687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.788505\ttraining's multi_logloss: 0.788505\tvalid_1's multi_logloss: 0.795687\tvalid_1's multi_logloss: 0.795687\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3922  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 312.3   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 32.47   \u001b[0m | \u001b[0m 34.88   \u001b[0m | \u001b[0m 0.6032  \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.769968\ttraining's multi_logloss: 0.769968\tvalid_1's multi_logloss: 0.795398\tvalid_1's multi_logloss: 0.795398\n",
      "[200]\ttraining's multi_logloss: 0.726975\ttraining's multi_logloss: 0.726975\tvalid_1's multi_logloss: 0.777616\tvalid_1's multi_logloss: 0.777616\n",
      "[300]\ttraining's multi_logloss: 0.696236\ttraining's multi_logloss: 0.696236\tvalid_1's multi_logloss: 0.767861\tvalid_1's multi_logloss: 0.767861\n",
      "[400]\ttraining's multi_logloss: 0.670968\ttraining's multi_logloss: 0.670968\tvalid_1's multi_logloss: 0.761625\tvalid_1's multi_logloss: 0.761625\n",
      "[500]\ttraining's multi_logloss: 0.650417\ttraining's multi_logloss: 0.650417\tvalid_1's multi_logloss: 0.756939\tvalid_1's multi_logloss: 0.756939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.650417\ttraining's multi_logloss: 0.650417\tvalid_1's multi_logloss: 0.756939\tvalid_1's multi_logloss: 0.756939\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.4279  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 34.42   \u001b[0m | \u001b[95m 16.0    \u001b[0m | \u001b[95m 195.9   \u001b[0m | \u001b[95m 50.0    \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.832606\ttraining's multi_logloss: 0.832606\tvalid_1's multi_logloss: 0.828988\tvalid_1's multi_logloss: 0.828988\n",
      "[200]\ttraining's multi_logloss: 0.820699\ttraining's multi_logloss: 0.820699\tvalid_1's multi_logloss: 0.817184\tvalid_1's multi_logloss: 0.817184\n",
      "[300]\ttraining's multi_logloss: 0.815624\ttraining's multi_logloss: 0.815624\tvalid_1's multi_logloss: 0.81249\tvalid_1's multi_logloss: 0.81249\n",
      "[400]\ttraining's multi_logloss: 0.813424\ttraining's multi_logloss: 0.813424\tvalid_1's multi_logloss: 0.810609\tvalid_1's multi_logloss: 0.810609\n",
      "[500]\ttraining's multi_logloss: 0.812393\ttraining's multi_logloss: 0.812393\tvalid_1's multi_logloss: 0.809657\tvalid_1's multi_logloss: 0.809657\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.812393\ttraining's multi_logloss: 0.812393\tvalid_1's multi_logloss: 0.809657\tvalid_1's multi_logloss: 0.809657\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3999  \u001b[0m | \u001b[0m 0.5589  \u001b[0m | \u001b[0m 15.7    \u001b[0m | \u001b[0m 7.225   \u001b[0m | \u001b[0m 18.73   \u001b[0m | \u001b[0m 1.035   \u001b[0m | \u001b[0m 23.17   \u001b[0m | \u001b[0m 43.08   \u001b[0m | \u001b[0m 3.653   \u001b[0m | \u001b[0m 0.8043  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.819415\ttraining's multi_logloss: 0.819415\tvalid_1's multi_logloss: 0.815929\tvalid_1's multi_logloss: 0.815929\n",
      "[200]\ttraining's multi_logloss: 0.8085\ttraining's multi_logloss: 0.8085\tvalid_1's multi_logloss: 0.805861\tvalid_1's multi_logloss: 0.805861\n",
      "[300]\ttraining's multi_logloss: 0.80358\ttraining's multi_logloss: 0.80358\tvalid_1's multi_logloss: 0.802406\tvalid_1's multi_logloss: 0.802406\n",
      "[400]\ttraining's multi_logloss: 0.801885\ttraining's multi_logloss: 0.801885\tvalid_1's multi_logloss: 0.80117\tvalid_1's multi_logloss: 0.80117\n",
      "[500]\ttraining's multi_logloss: 0.801471\ttraining's multi_logloss: 0.801471\tvalid_1's multi_logloss: 0.800792\tvalid_1's multi_logloss: 0.800792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.801471\ttraining's multi_logloss: 0.801471\tvalid_1's multi_logloss: 0.800792\tvalid_1's multi_logloss: 0.800792\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.3912  \u001b[0m | \u001b[0m 0.8231  \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 9.738   \u001b[0m | \u001b[0m 135.2   \u001b[0m | \u001b[0m 47.24   \u001b[0m | \u001b[0m 62.99   \u001b[0m | \u001b[0m 48.95   \u001b[0m | \u001b[0m 5.487   \u001b[0m | \u001b[0m 0.6267  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.810925\ttraining's multi_logloss: 0.810925\tvalid_1's multi_logloss: 0.815196\tvalid_1's multi_logloss: 0.815196\n",
      "[200]\ttraining's multi_logloss: 0.783763\ttraining's multi_logloss: 0.783763\tvalid_1's multi_logloss: 0.797745\tvalid_1's multi_logloss: 0.797745\n",
      "[300]\ttraining's multi_logloss: 0.764607\ttraining's multi_logloss: 0.764607\tvalid_1's multi_logloss: 0.788731\tvalid_1's multi_logloss: 0.788731\n",
      "[400]\ttraining's multi_logloss: 0.749935\ttraining's multi_logloss: 0.749935\tvalid_1's multi_logloss: 0.782994\tvalid_1's multi_logloss: 0.782994\n",
      "[500]\ttraining's multi_logloss: 0.737888\ttraining's multi_logloss: 0.737888\tvalid_1's multi_logloss: 0.77932\tvalid_1's multi_logloss: 0.77932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.737888\ttraining's multi_logloss: 0.737888\tvalid_1's multi_logloss: 0.77932\tvalid_1's multi_logloss: 0.77932\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.3917  \u001b[0m | \u001b[0m 0.6061  \u001b[0m | \u001b[0m 12.99   \u001b[0m | \u001b[0m 8.237   \u001b[0m | \u001b[0m 12.66   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 59.39   \u001b[0m | \u001b[0m 7.411   \u001b[0m | \u001b[0m 5.663   \u001b[0m | \u001b[0m 0.9739  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.797076\ttraining's multi_logloss: 0.797076\tvalid_1's multi_logloss: 0.805986\tvalid_1's multi_logloss: 0.805986\n",
      "[200]\ttraining's multi_logloss: 0.769022\ttraining's multi_logloss: 0.769022\tvalid_1's multi_logloss: 0.790817\tvalid_1's multi_logloss: 0.790817\n",
      "[300]\ttraining's multi_logloss: 0.74983\ttraining's multi_logloss: 0.74983\tvalid_1's multi_logloss: 0.783615\tvalid_1's multi_logloss: 0.783615\n",
      "[400]\ttraining's multi_logloss: 0.733144\ttraining's multi_logloss: 0.733144\tvalid_1's multi_logloss: 0.777844\tvalid_1's multi_logloss: 0.777844\n",
      "[500]\ttraining's multi_logloss: 0.719054\ttraining's multi_logloss: 0.719054\tvalid_1's multi_logloss: 0.77377\tvalid_1's multi_logloss: 0.77377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.719054\ttraining's multi_logloss: 0.719054\tvalid_1's multi_logloss: 0.77377\tvalid_1's multi_logloss: 0.77377\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3986  \u001b[0m | \u001b[0m 0.7805  \u001b[0m | \u001b[0m 28.96   \u001b[0m | \u001b[0m 8.223   \u001b[0m | \u001b[0m 179.4   \u001b[0m | \u001b[0m 37.64   \u001b[0m | \u001b[0m 59.79   \u001b[0m | \u001b[0m 6.065   \u001b[0m | \u001b[0m 2.774   \u001b[0m | \u001b[0m 0.6177  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.81903\ttraining's multi_logloss: 0.81903\tvalid_1's multi_logloss: 0.819993\tvalid_1's multi_logloss: 0.819993\n",
      "[200]\ttraining's multi_logloss: 0.798619\ttraining's multi_logloss: 0.798619\tvalid_1's multi_logloss: 0.803864\tvalid_1's multi_logloss: 0.803864\n",
      "[300]\ttraining's multi_logloss: 0.786576\ttraining's multi_logloss: 0.786576\tvalid_1's multi_logloss: 0.796408\tvalid_1's multi_logloss: 0.796408\n",
      "[400]\ttraining's multi_logloss: 0.777653\ttraining's multi_logloss: 0.777653\tvalid_1's multi_logloss: 0.791921\tvalid_1's multi_logloss: 0.791921\n",
      "[500]\ttraining's multi_logloss: 0.770062\ttraining's multi_logloss: 0.770062\tvalid_1's multi_logloss: 0.788673\tvalid_1's multi_logloss: 0.788673\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.770062\ttraining's multi_logloss: 0.770062\tvalid_1's multi_logloss: 0.788673\tvalid_1's multi_logloss: 0.788673\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.3941  \u001b[0m | \u001b[0m 0.5314  \u001b[0m | \u001b[0m 494.6   \u001b[0m | \u001b[0m 7.665   \u001b[0m | \u001b[0m 14.36   \u001b[0m | \u001b[0m 2.408   \u001b[0m | \u001b[0m 13.16   \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 5.293   \u001b[0m | \u001b[0m 0.7669  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.787147\ttraining's multi_logloss: 0.787147\tvalid_1's multi_logloss: 0.803048\tvalid_1's multi_logloss: 0.803048\n",
      "[200]\ttraining's multi_logloss: 0.75078\ttraining's multi_logloss: 0.75078\tvalid_1's multi_logloss: 0.783588\tvalid_1's multi_logloss: 0.783588\n",
      "[300]\ttraining's multi_logloss: 0.725283\ttraining's multi_logloss: 0.725283\tvalid_1's multi_logloss: 0.77355\tvalid_1's multi_logloss: 0.77355\n",
      "[400]\ttraining's multi_logloss: 0.706401\ttraining's multi_logloss: 0.706401\tvalid_1's multi_logloss: 0.767495\tvalid_1's multi_logloss: 0.767495\n",
      "[500]\ttraining's multi_logloss: 0.689388\ttraining's multi_logloss: 0.689388\tvalid_1's multi_logloss: 0.761887\tvalid_1's multi_logloss: 0.761887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.689388\ttraining's multi_logloss: 0.689388\tvalid_1's multi_logloss: 0.761887\tvalid_1's multi_logloss: 0.761887\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.4075  \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 444.7   \u001b[0m | \u001b[0m 8.743   \u001b[0m | \u001b[0m 159.9   \u001b[0m | \u001b[0m 17.34   \u001b[0m | \u001b[0m 46.34   \u001b[0m | \u001b[0m 4.481   \u001b[0m | \u001b[0m 3.524   \u001b[0m | \u001b[0m 0.5199  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.822002\ttraining's multi_logloss: 0.822002\tvalid_1's multi_logloss: 0.822137\tvalid_1's multi_logloss: 0.822137\n",
      "[200]\ttraining's multi_logloss: 0.801329\ttraining's multi_logloss: 0.801329\tvalid_1's multi_logloss: 0.804865\tvalid_1's multi_logloss: 0.804865\n",
      "[300]\ttraining's multi_logloss: 0.789912\ttraining's multi_logloss: 0.789912\tvalid_1's multi_logloss: 0.797372\tvalid_1's multi_logloss: 0.797372\n",
      "[400]\ttraining's multi_logloss: 0.781898\ttraining's multi_logloss: 0.781898\tvalid_1's multi_logloss: 0.793326\tvalid_1's multi_logloss: 0.793326\n",
      "[500]\ttraining's multi_logloss: 0.775166\ttraining's multi_logloss: 0.775166\tvalid_1's multi_logloss: 0.79055\tvalid_1's multi_logloss: 0.79055\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.775166\ttraining's multi_logloss: 0.775166\tvalid_1's multi_logloss: 0.79055\tvalid_1's multi_logloss: 0.79055\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.3945  \u001b[0m | \u001b[0m 0.5175  \u001b[0m | \u001b[0m 122.8   \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 182.9   \u001b[0m | \u001b[0m 4.801   \u001b[0m | \u001b[0m 8.696   \u001b[0m | \u001b[0m 1.974   \u001b[0m | \u001b[0m 6.267   \u001b[0m | \u001b[0m 0.5975  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.827652\ttraining's multi_logloss: 0.827652\tvalid_1's multi_logloss: 0.823427\tvalid_1's multi_logloss: 0.823427\n",
      "[200]\ttraining's multi_logloss: 0.814366\ttraining's multi_logloss: 0.814366\tvalid_1's multi_logloss: 0.81026\tvalid_1's multi_logloss: 0.81026\n",
      "[300]\ttraining's multi_logloss: 0.80881\ttraining's multi_logloss: 0.80881\tvalid_1's multi_logloss: 0.805274\tvalid_1's multi_logloss: 0.805274\n",
      "[400]\ttraining's multi_logloss: 0.806671\ttraining's multi_logloss: 0.806671\tvalid_1's multi_logloss: 0.803339\tvalid_1's multi_logloss: 0.803339\n",
      "[500]\ttraining's multi_logloss: 0.80576\ttraining's multi_logloss: 0.80576\tvalid_1's multi_logloss: 0.80244\tvalid_1's multi_logloss: 0.80244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.80576\ttraining's multi_logloss: 0.80576\tvalid_1's multi_logloss: 0.80244\tvalid_1's multi_logloss: 0.80244\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3892  \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 53.52   \u001b[0m | \u001b[0m 15.79   \u001b[0m | \u001b[0m 46.05   \u001b[0m | \u001b[0m 48.14   \u001b[0m | \u001b[0m 11.27   \u001b[0m | \u001b[0m 49.42   \u001b[0m | \u001b[0m 8.351   \u001b[0m | \u001b[0m 0.8539  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.797099\ttraining's multi_logloss: 0.797099\tvalid_1's multi_logloss: 0.81088\tvalid_1's multi_logloss: 0.81088\n",
      "[200]\ttraining's multi_logloss: 0.758424\ttraining's multi_logloss: 0.758424\tvalid_1's multi_logloss: 0.788897\tvalid_1's multi_logloss: 0.788897\n",
      "[300]\ttraining's multi_logloss: 0.731276\ttraining's multi_logloss: 0.731276\tvalid_1's multi_logloss: 0.777451\tvalid_1's multi_logloss: 0.777451\n",
      "[400]\ttraining's multi_logloss: 0.708417\ttraining's multi_logloss: 0.708417\tvalid_1's multi_logloss: 0.769198\tvalid_1's multi_logloss: 0.769198\n",
      "[500]\ttraining's multi_logloss: 0.689312\ttraining's multi_logloss: 0.689312\tvalid_1's multi_logloss: 0.762913\tvalid_1's multi_logloss: 0.762913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.689312\ttraining's multi_logloss: 0.689312\tvalid_1's multi_logloss: 0.762913\tvalid_1's multi_logloss: 0.762913\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4074  \u001b[0m | \u001b[0m 0.5217  \u001b[0m | \u001b[0m 274.1   \u001b[0m | \u001b[0m 15.84   \u001b[0m | \u001b[0m 198.1   \u001b[0m | \u001b[0m 46.41   \u001b[0m | \u001b[0m 61.91   \u001b[0m | \u001b[0m 5.958   \u001b[0m | \u001b[0m 7.456   \u001b[0m | \u001b[0m 0.6905  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.814189\ttraining's multi_logloss: 0.814189\tvalid_1's multi_logloss: 0.812537\tvalid_1's multi_logloss: 0.812537\n",
      "[200]\ttraining's multi_logloss: 0.798707\ttraining's multi_logloss: 0.798707\tvalid_1's multi_logloss: 0.800656\tvalid_1's multi_logloss: 0.800656\n",
      "[300]\ttraining's multi_logloss: 0.790401\ttraining's multi_logloss: 0.790401\tvalid_1's multi_logloss: 0.796147\tvalid_1's multi_logloss: 0.796147\n",
      "[400]\ttraining's multi_logloss: 0.783937\ttraining's multi_logloss: 0.783937\tvalid_1's multi_logloss: 0.793352\tvalid_1's multi_logloss: 0.793352\n",
      "[500]\ttraining's multi_logloss: 0.77837\ttraining's multi_logloss: 0.77837\tvalid_1's multi_logloss: 0.791125\tvalid_1's multi_logloss: 0.791125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.77837\ttraining's multi_logloss: 0.77837\tvalid_1's multi_logloss: 0.791125\tvalid_1's multi_logloss: 0.791125\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.3921  \u001b[0m | \u001b[0m 0.7902  \u001b[0m | \u001b[0m 498.6   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 189.8   \u001b[0m | \u001b[0m 7.88    \u001b[0m | \u001b[0m 8.921   \u001b[0m | \u001b[0m 10.45   \u001b[0m | \u001b[0m 7.971   \u001b[0m | \u001b[0m 0.7325  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.759086\ttraining's multi_logloss: 0.759086\tvalid_1's multi_logloss: 0.793014\tvalid_1's multi_logloss: 0.793014\n",
      "[200]\ttraining's multi_logloss: 0.703866\ttraining's multi_logloss: 0.703866\tvalid_1's multi_logloss: 0.767828\tvalid_1's multi_logloss: 0.767828\n",
      "[300]\ttraining's multi_logloss: 0.66618\ttraining's multi_logloss: 0.66618\tvalid_1's multi_logloss: 0.755095\tvalid_1's multi_logloss: 0.755095\n",
      "[400]\ttraining's multi_logloss: 0.636049\ttraining's multi_logloss: 0.636049\tvalid_1's multi_logloss: 0.746444\tvalid_1's multi_logloss: 0.746444\n",
      "[500]\ttraining's multi_logloss: 0.610916\ttraining's multi_logloss: 0.610916\tvalid_1's multi_logloss: 0.740422\tvalid_1's multi_logloss: 0.740422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.610916\ttraining's multi_logloss: 0.610916\tvalid_1's multi_logloss: 0.740422\tvalid_1's multi_logloss: 0.740422\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.4496  \u001b[0m | \u001b[95m 0.6061  \u001b[0m | \u001b[95m 334.3   \u001b[0m | \u001b[95m 15.97   \u001b[0m | \u001b[95m 20.67   \u001b[0m | \u001b[95m 15.01   \u001b[0m | \u001b[95m 62.35   \u001b[0m | \u001b[95m 1.801   \u001b[0m | \u001b[95m 4.06    \u001b[0m | \u001b[95m 0.5817  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.771303\ttraining's multi_logloss: 0.771303\tvalid_1's multi_logloss: 0.795369\tvalid_1's multi_logloss: 0.795369\n",
      "[200]\ttraining's multi_logloss: 0.727071\ttraining's multi_logloss: 0.727071\tvalid_1's multi_logloss: 0.773999\tvalid_1's multi_logloss: 0.773999\n",
      "[300]\ttraining's multi_logloss: 0.69722\ttraining's multi_logloss: 0.69722\tvalid_1's multi_logloss: 0.763819\tvalid_1's multi_logloss: 0.763819\n",
      "[400]\ttraining's multi_logloss: 0.67346\ttraining's multi_logloss: 0.67346\tvalid_1's multi_logloss: 0.756777\tvalid_1's multi_logloss: 0.756777\n",
      "[500]\ttraining's multi_logloss: 0.651828\ttraining's multi_logloss: 0.651828\tvalid_1's multi_logloss: 0.750938\tvalid_1's multi_logloss: 0.750938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.651828\ttraining's multi_logloss: 0.651828\tvalid_1's multi_logloss: 0.750938\tvalid_1's multi_logloss: 0.750938\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4287  \u001b[0m | \u001b[0m 0.712   \u001b[0m | \u001b[0m 135.4   \u001b[0m | \u001b[0m 15.34   \u001b[0m | \u001b[0m 19.87   \u001b[0m | \u001b[0m 1.882   \u001b[0m | \u001b[0m 46.86   \u001b[0m | \u001b[0m 3.744   \u001b[0m | \u001b[0m 1.535   \u001b[0m | \u001b[0m 0.9527  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.795118\ttraining's multi_logloss: 0.795118\tvalid_1's multi_logloss: 0.809913\tvalid_1's multi_logloss: 0.809913\n",
      "[200]\ttraining's multi_logloss: 0.758565\ttraining's multi_logloss: 0.758565\tvalid_1's multi_logloss: 0.788506\tvalid_1's multi_logloss: 0.788506\n",
      "[300]\ttraining's multi_logloss: 0.733435\ttraining's multi_logloss: 0.733435\tvalid_1's multi_logloss: 0.777808\tvalid_1's multi_logloss: 0.777808\n",
      "[400]\ttraining's multi_logloss: 0.714452\ttraining's multi_logloss: 0.714452\tvalid_1's multi_logloss: 0.770707\tvalid_1's multi_logloss: 0.770707\n",
      "[500]\ttraining's multi_logloss: 0.698439\ttraining's multi_logloss: 0.698439\tvalid_1's multi_logloss: 0.765306\tvalid_1's multi_logloss: 0.765306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.698439\ttraining's multi_logloss: 0.698439\tvalid_1's multi_logloss: 0.765306\tvalid_1's multi_logloss: 0.765306\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.4044  \u001b[0m | \u001b[0m 0.5477  \u001b[0m | \u001b[0m 279.6   \u001b[0m | \u001b[0m 10.26   \u001b[0m | \u001b[0m 196.8   \u001b[0m | \u001b[0m 46.28   \u001b[0m | \u001b[0m 59.54   \u001b[0m | \u001b[0m 4.305   \u001b[0m | \u001b[0m 6.443   \u001b[0m | \u001b[0m 0.8331  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.773119\ttraining's multi_logloss: 0.773119\tvalid_1's multi_logloss: 0.7952\tvalid_1's multi_logloss: 0.7952\n",
      "[200]\ttraining's multi_logloss: 0.730433\ttraining's multi_logloss: 0.730433\tvalid_1's multi_logloss: 0.7764\tvalid_1's multi_logloss: 0.7764\n",
      "[300]\ttraining's multi_logloss: 0.699343\ttraining's multi_logloss: 0.699343\tvalid_1's multi_logloss: 0.765399\tvalid_1's multi_logloss: 0.765399\n",
      "[400]\ttraining's multi_logloss: 0.674831\ttraining's multi_logloss: 0.674831\tvalid_1's multi_logloss: 0.757779\tvalid_1's multi_logloss: 0.757779\n",
      "[500]\ttraining's multi_logloss: 0.655692\ttraining's multi_logloss: 0.655692\tvalid_1's multi_logloss: 0.752999\tvalid_1's multi_logloss: 0.752999\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.655692\ttraining's multi_logloss: 0.655692\tvalid_1's multi_logloss: 0.752999\tvalid_1's multi_logloss: 0.752999\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.4244  \u001b[0m | \u001b[0m 0.9918  \u001b[0m | \u001b[0m 495.7   \u001b[0m | \u001b[0m 15.47   \u001b[0m | \u001b[0m 22.48   \u001b[0m | \u001b[0m 47.76   \u001b[0m | \u001b[0m 57.44   \u001b[0m | \u001b[0m 5.65    \u001b[0m | \u001b[0m 3.964   \u001b[0m | \u001b[0m 0.6183  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.824659\ttraining's multi_logloss: 0.824659\tvalid_1's multi_logloss: 0.824132\tvalid_1's multi_logloss: 0.824132\n",
      "[200]\ttraining's multi_logloss: 0.809774\ttraining's multi_logloss: 0.809774\tvalid_1's multi_logloss: 0.81295\tvalid_1's multi_logloss: 0.81295\n",
      "[300]\ttraining's multi_logloss: 0.801609\ttraining's multi_logloss: 0.801609\tvalid_1's multi_logloss: 0.809208\tvalid_1's multi_logloss: 0.809208\n",
      "[400]\ttraining's multi_logloss: 0.795429\ttraining's multi_logloss: 0.795429\tvalid_1's multi_logloss: 0.806776\tvalid_1's multi_logloss: 0.806776\n",
      "[500]\ttraining's multi_logloss: 0.790609\ttraining's multi_logloss: 0.790609\tvalid_1's multi_logloss: 0.805149\tvalid_1's multi_logloss: 0.805149\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.790609\ttraining's multi_logloss: 0.790609\tvalid_1's multi_logloss: 0.805149\tvalid_1's multi_logloss: 0.805149\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.3999  \u001b[0m | \u001b[0m 0.6163  \u001b[0m | \u001b[0m 10.44   \u001b[0m | \u001b[0m 10.6    \u001b[0m | \u001b[0m 185.8   \u001b[0m | \u001b[0m 49.56   \u001b[0m | \u001b[0m 16.21   \u001b[0m | \u001b[0m 9.978   \u001b[0m | \u001b[0m 9.358   \u001b[0m | \u001b[0m 0.5858  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.813805\ttraining's multi_logloss: 0.813805\tvalid_1's multi_logloss: 0.811862\tvalid_1's multi_logloss: 0.811862\n",
      "[200]\ttraining's multi_logloss: 0.800066\ttraining's multi_logloss: 0.800066\tvalid_1's multi_logloss: 0.801592\tvalid_1's multi_logloss: 0.801592\n",
      "[300]\ttraining's multi_logloss: 0.793241\ttraining's multi_logloss: 0.793241\tvalid_1's multi_logloss: 0.797943\tvalid_1's multi_logloss: 0.797943\n",
      "[400]\ttraining's multi_logloss: 0.789322\ttraining's multi_logloss: 0.789322\tvalid_1's multi_logloss: 0.796177\tvalid_1's multi_logloss: 0.796177\n",
      "[500]\ttraining's multi_logloss: 0.787529\ttraining's multi_logloss: 0.787529\tvalid_1's multi_logloss: 0.795467\tvalid_1's multi_logloss: 0.795467\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.787529\ttraining's multi_logloss: 0.787529\tvalid_1's multi_logloss: 0.795467\tvalid_1's multi_logloss: 0.795467\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.3933  \u001b[0m | \u001b[0m 0.9983  \u001b[0m | \u001b[0m 254.0   \u001b[0m | \u001b[0m 15.65   \u001b[0m | \u001b[0m 172.3   \u001b[0m | \u001b[0m 4.75    \u001b[0m | \u001b[0m 24.8    \u001b[0m | \u001b[0m 34.22   \u001b[0m | \u001b[0m 8.13    \u001b[0m | \u001b[0m 0.8197  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.787633\ttraining's multi_logloss: 0.787633\tvalid_1's multi_logloss: 0.805187\tvalid_1's multi_logloss: 0.805187\n",
      "[200]\ttraining's multi_logloss: 0.747701\ttraining's multi_logloss: 0.747701\tvalid_1's multi_logloss: 0.783753\tvalid_1's multi_logloss: 0.783753\n",
      "[300]\ttraining's multi_logloss: 0.719502\ttraining's multi_logloss: 0.719502\tvalid_1's multi_logloss: 0.771975\tvalid_1's multi_logloss: 0.771975\n",
      "[400]\ttraining's multi_logloss: 0.696629\ttraining's multi_logloss: 0.696629\tvalid_1's multi_logloss: 0.764\tvalid_1's multi_logloss: 0.764\n",
      "[500]\ttraining's multi_logloss: 0.67766\ttraining's multi_logloss: 0.67766\tvalid_1's multi_logloss: 0.758082\tvalid_1's multi_logloss: 0.758082\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.67766\ttraining's multi_logloss: 0.67766\tvalid_1's multi_logloss: 0.758082\tvalid_1's multi_logloss: 0.758082\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 0.5971  \u001b[0m | \u001b[0m 447.9   \u001b[0m | \u001b[0m 13.34   \u001b[0m | \u001b[0m 168.5   \u001b[0m | \u001b[0m 19.35   \u001b[0m | \u001b[0m 45.89   \u001b[0m | \u001b[0m 4.679   \u001b[0m | \u001b[0m 6.172   \u001b[0m | \u001b[0m 0.6255  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.827774\ttraining's multi_logloss: 0.827774\tvalid_1's multi_logloss: 0.824514\tvalid_1's multi_logloss: 0.824514\n",
      "[200]\ttraining's multi_logloss: 0.813173\ttraining's multi_logloss: 0.813173\tvalid_1's multi_logloss: 0.810704\tvalid_1's multi_logloss: 0.810704\n",
      "[300]\ttraining's multi_logloss: 0.80675\ttraining's multi_logloss: 0.80675\tvalid_1's multi_logloss: 0.805212\tvalid_1's multi_logloss: 0.805212\n",
      "[400]\ttraining's multi_logloss: 0.804364\ttraining's multi_logloss: 0.804364\tvalid_1's multi_logloss: 0.803106\tvalid_1's multi_logloss: 0.803106\n",
      "[500]\ttraining's multi_logloss: 0.803371\ttraining's multi_logloss: 0.803371\tvalid_1's multi_logloss: 0.802131\tvalid_1's multi_logloss: 0.802131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\ttraining's multi_logloss: 0.803371\ttraining's multi_logloss: 0.803371\tvalid_1's multi_logloss: 0.802131\tvalid_1's multi_logloss: 0.802131\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.5907  \u001b[0m | \u001b[0m 217.3   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 2.35    \u001b[0m | \u001b[0m 51.16   \u001b[0m | \u001b[0m 49.29   \u001b[0m | \u001b[0m 9.421   \u001b[0m | \u001b[0m 0.5156  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.77967\ttraining's multi_logloss: 0.77967\tvalid_1's multi_logloss: 0.797483\tvalid_1's multi_logloss: 0.797483\n",
      "[200]\ttraining's multi_logloss: 0.745855\ttraining's multi_logloss: 0.745855\tvalid_1's multi_logloss: 0.782032\tvalid_1's multi_logloss: 0.782032\n",
      "[300]\ttraining's multi_logloss: 0.722036\ttraining's multi_logloss: 0.722036\tvalid_1's multi_logloss: 0.773498\tvalid_1's multi_logloss: 0.773498\n",
      "[400]\ttraining's multi_logloss: 0.701845\ttraining's multi_logloss: 0.701845\tvalid_1's multi_logloss: 0.766028\tvalid_1's multi_logloss: 0.766028\n",
      "[500]\ttraining's multi_logloss: 0.685449\ttraining's multi_logloss: 0.685449\tvalid_1's multi_logloss: 0.76122\tvalid_1's multi_logloss: 0.76122\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.685449\ttraining's multi_logloss: 0.685449\tvalid_1's multi_logloss: 0.76122\tvalid_1's multi_logloss: 0.76122\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.4117  \u001b[0m | \u001b[0m 0.9848  \u001b[0m | \u001b[0m 443.2   \u001b[0m | \u001b[0m 9.118   \u001b[0m | \u001b[0m 173.9   \u001b[0m | \u001b[0m 15.34   \u001b[0m | \u001b[0m 48.25   \u001b[0m | \u001b[0m 3.682   \u001b[0m | \u001b[0m 1.571   \u001b[0m | \u001b[0m 0.5959  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.806291\ttraining's multi_logloss: 0.806291\tvalid_1's multi_logloss: 0.811684\tvalid_1's multi_logloss: 0.811684\n",
      "[200]\ttraining's multi_logloss: 0.780524\ttraining's multi_logloss: 0.780524\tvalid_1's multi_logloss: 0.794575\tvalid_1's multi_logloss: 0.794575\n",
      "[300]\ttraining's multi_logloss: 0.764022\ttraining's multi_logloss: 0.764022\tvalid_1's multi_logloss: 0.786314\tvalid_1's multi_logloss: 0.786314\n",
      "[400]\ttraining's multi_logloss: 0.750645\ttraining's multi_logloss: 0.750645\tvalid_1's multi_logloss: 0.780602\tvalid_1's multi_logloss: 0.780602\n",
      "[500]\ttraining's multi_logloss: 0.738816\ttraining's multi_logloss: 0.738816\tvalid_1's multi_logloss: 0.775945\tvalid_1's multi_logloss: 0.775945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.738816\ttraining's multi_logloss: 0.738816\tvalid_1's multi_logloss: 0.775945\tvalid_1's multi_logloss: 0.775945\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.395   \u001b[0m | \u001b[0m 0.5941  \u001b[0m | \u001b[0m 268.6   \u001b[0m | \u001b[0m 13.24   \u001b[0m | \u001b[0m 12.23   \u001b[0m | \u001b[0m 11.75   \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 1.918   \u001b[0m | \u001b[0m 0.6283  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.820178\ttraining's multi_logloss: 0.820178\tvalid_1's multi_logloss: 0.816036\tvalid_1's multi_logloss: 0.816036\n",
      "[200]\ttraining's multi_logloss: 0.811381\ttraining's multi_logloss: 0.811381\tvalid_1's multi_logloss: 0.807646\tvalid_1's multi_logloss: 0.807646\n",
      "[300]\ttraining's multi_logloss: 0.808073\ttraining's multi_logloss: 0.808073\tvalid_1's multi_logloss: 0.804937\tvalid_1's multi_logloss: 0.804937\n",
      "[400]\ttraining's multi_logloss: 0.806944\ttraining's multi_logloss: 0.806944\tvalid_1's multi_logloss: 0.803974\tvalid_1's multi_logloss: 0.803974\n",
      "[500]\ttraining's multi_logloss: 0.806537\ttraining's multi_logloss: 0.806537\tvalid_1's multi_logloss: 0.803635\tvalid_1's multi_logloss: 0.803635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.806537\ttraining's multi_logloss: 0.806537\tvalid_1's multi_logloss: 0.803635\tvalid_1's multi_logloss: 0.803635\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.389   \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 24.29   \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 193.6   \u001b[0m | \u001b[0m 35.64   \u001b[0m | \u001b[0m 56.31   \u001b[0m | \u001b[0m 49.59   \u001b[0m | \u001b[0m 7.593   \u001b[0m | \u001b[0m 0.8657  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.768912\ttraining's multi_logloss: 0.768912\tvalid_1's multi_logloss: 0.794668\tvalid_1's multi_logloss: 0.794668\n",
      "[200]\ttraining's multi_logloss: 0.722322\ttraining's multi_logloss: 0.722322\tvalid_1's multi_logloss: 0.773129\tvalid_1's multi_logloss: 0.773129\n",
      "[300]\ttraining's multi_logloss: 0.690134\ttraining's multi_logloss: 0.690134\tvalid_1's multi_logloss: 0.76182\tvalid_1's multi_logloss: 0.76182\n",
      "[400]\ttraining's multi_logloss: 0.664064\ttraining's multi_logloss: 0.664064\tvalid_1's multi_logloss: 0.754315\tvalid_1's multi_logloss: 0.754315\n",
      "[500]\ttraining's multi_logloss: 0.643005\ttraining's multi_logloss: 0.643005\tvalid_1's multi_logloss: 0.748935\tvalid_1's multi_logloss: 0.748935\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.643005\ttraining's multi_logloss: 0.643005\tvalid_1's multi_logloss: 0.748935\tvalid_1's multi_logloss: 0.748935\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.4341  \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 424.4   \u001b[0m | \u001b[0m 15.06   \u001b[0m | \u001b[0m 14.38   \u001b[0m | \u001b[0m 7.972   \u001b[0m | \u001b[0m 62.57   \u001b[0m | \u001b[0m 6.074   \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 0.7597  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.750663\ttraining's multi_logloss: 0.750663\tvalid_1's multi_logloss: 0.787771\tvalid_1's multi_logloss: 0.787771\n",
      "[200]\ttraining's multi_logloss: 0.695277\ttraining's multi_logloss: 0.695277\tvalid_1's multi_logloss: 0.76453\tvalid_1's multi_logloss: 0.76453\n",
      "[300]\ttraining's multi_logloss: 0.6572\ttraining's multi_logloss: 0.6572\tvalid_1's multi_logloss: 0.753172\tvalid_1's multi_logloss: 0.753172\n",
      "[400]\ttraining's multi_logloss: 0.626733\ttraining's multi_logloss: 0.626733\tvalid_1's multi_logloss: 0.745677\tvalid_1's multi_logloss: 0.745677\n",
      "[500]\ttraining's multi_logloss: 0.601958\ttraining's multi_logloss: 0.601958\tvalid_1's multi_logloss: 0.740013\tvalid_1's multi_logloss: 0.740013\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.601958\ttraining's multi_logloss: 0.601958\tvalid_1's multi_logloss: 0.740013\tvalid_1's multi_logloss: 0.740013\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.4593  \u001b[0m | \u001b[95m 0.7675  \u001b[0m | \u001b[95m 269.6   \u001b[0m | \u001b[95m 13.9    \u001b[0m | \u001b[95m 68.27   \u001b[0m | \u001b[95m 9.013   \u001b[0m | \u001b[95m 63.15   \u001b[0m | \u001b[95m 1.764   \u001b[0m | \u001b[95m 0.6887  \u001b[0m | \u001b[95m 0.501   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.762417\ttraining's multi_logloss: 0.762417\tvalid_1's multi_logloss: 0.79518\tvalid_1's multi_logloss: 0.79518\n",
      "[200]\ttraining's multi_logloss: 0.709789\ttraining's multi_logloss: 0.709789\tvalid_1's multi_logloss: 0.770448\tvalid_1's multi_logloss: 0.770448\n",
      "[300]\ttraining's multi_logloss: 0.673662\ttraining's multi_logloss: 0.673662\tvalid_1's multi_logloss: 0.757853\tvalid_1's multi_logloss: 0.757853\n",
      "[400]\ttraining's multi_logloss: 0.645055\ttraining's multi_logloss: 0.645055\tvalid_1's multi_logloss: 0.749302\tvalid_1's multi_logloss: 0.749302\n",
      "[500]\ttraining's multi_logloss: 0.621648\ttraining's multi_logloss: 0.621648\tvalid_1's multi_logloss: 0.743416\tvalid_1's multi_logloss: 0.743416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's multi_logloss: 0.621648\ttraining's multi_logloss: 0.621648\tvalid_1's multi_logloss: 0.743416\tvalid_1's multi_logloss: 0.743416\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.4452  \u001b[0m | \u001b[0m 0.6069  \u001b[0m | \u001b[0m 499.3   \u001b[0m | \u001b[0m 11.71   \u001b[0m | \u001b[0m 79.52   \u001b[0m | \u001b[0m 4.651   \u001b[0m | \u001b[0m 63.13   \u001b[0m | \u001b[0m 2.651   \u001b[0m | \u001b[0m 1.004   \u001b[0m | \u001b[0m 0.5101  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# BayesianOptimization객체를 수행할 함수와 search할 parameter 범위를 설정하여 생성. \n",
    "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=0)\n",
    "# 함수 반환값이 최대가 되는 입력값 유추를 위한 iteration 수행. \n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16lhW6ZSJjol"
   },
   "outputs": [],
   "source": [
    "# # BayesianOptimization객체의 res는 iteration 수행 시마다 모든 함수 반환결과와 그때의 파라미터 결과값을 가지고 있음. \n",
    "# lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61C1XY2hJoE6",
    "outputId": "bb44eae4-c48c-4675-d3c9-9b05c9df3719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39310358423113767, 0.39441700260112666, 0.4254950004385709, 0.39398746212125385, 0.39218605591475236, 0.4278552654364703, 0.39986437152144205, 0.39123488405038903, 0.39166532916031355, 0.39858666492111744, 0.3940661137894117, 0.4074813165507636, 0.39447691184675, 0.38915740945661303, 0.40743508524875766, 0.392053098098796, 0.44955335795197554, 0.42868147447494015, 0.40435639122005035, 0.424382549450906, 0.39986437152144205, 0.3932907064266746, 0.41667842790265697, 0.39193983365856305, 0.41171917313673373, 0.3949625879008734, 0.38898929574544877, 0.43412238698385447, 0.4592501526858131, 0.4451859331322828]\n",
      "maximum target index: 28\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmax(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwHuU8LkJxAP",
    "outputId": "5bd5772e-4f23-417a-942c-77e63e925261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.4592501526858131, 'params': {'colsample_bytree': 0.7674567512954314, 'max_bin': 269.6109200398602, 'max_depth': 13.896975914831401, 'min_child_samples': 68.26720342186422, 'min_child_weight': 9.013217831887559, 'num_leaves': 63.152516494223335, 'reg_alpha': 1.7639768328775685, 'reg_lambda': 0.688724140896305, 'subsample': 0.5009743194948411}}\n"
     ]
    }
   ],
   "source": [
    "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Onk3TMdaFPD5"
   },
   "source": [
    "#### 5-2 최적의 파라미터로 학습/예측 한번만 시행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4Nb2EhbLgj3"
   },
   "outputs": [],
   "source": [
    "# 최적화된 하이퍼 파라미터를 기반으로 재 테스트\n",
    "# tunning_5 버전 \n",
    "def train_all(train):\n",
    "    ftr_train = train.drop(['index', 'credit'], axis=1)\n",
    "    target_train = train['credit']\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_train, target_train, test_size=0.3, random_state=2020)\n",
    "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
    "    clf = LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                max_depth = 15,\n",
    "                num_leaves=58,\n",
    "                colsample_bytree=0.870,\n",
    "                subsample=0.674,\n",
    "                max_bin=91,\n",
    "                reg_alpha=1.841,\n",
    "                reg_lambda=0.039,\n",
    "                min_child_weight=2,\n",
    "                min_child_samples=13,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCQm4BcGTD9Q"
   },
   "outputs": [],
   "source": [
    "# 최적화된 하이퍼 파라미터를 기반으로 재 테스트\n",
    "# tunning_3_2 버전 \n",
    "def train_all(train):\n",
    "    ftr_train = train.drop(['index', 'credit'], axis=1)\n",
    "    target_train = train['credit']\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_train, target_train, test_size=0.3, random_state=2020)\n",
    "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
    "    clf = LGBMClassifier(\n",
    "                nthread=4,\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.02,\n",
    "                max_depth = 14,\n",
    "                num_leaves=63,\n",
    "                colsample_bytree=0.767,\n",
    "                subsample=0.501,\n",
    "                max_bin=270,\n",
    "                reg_alpha=1.764,\n",
    "                reg_lambda=0.689,\n",
    "                min_child_weight=9,\n",
    "                min_child_samples=68,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zV3K5FMzeQKN",
    "outputId": "ec720910-4ee3-4bf2-db76-00b1281a94e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 30), (10000, 29))"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data[~data['credit'].isnull()]\n",
    "test = data[data['credit'].isnull()]\n",
    "test = test.drop('credit', axis=1)\n",
    "train.shape , test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6I90N7ed0x8",
    "outputId": "54c77b43-5975-475b-b908-520fc639aeb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (18519, 28) valid shape: (7938, 28)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.747335\ttraining's multi_logloss: 0.747335\tvalid_1's multi_logloss: 0.796219\tvalid_1's multi_logloss: 0.796219\n",
      "[200]\ttraining's multi_logloss: 0.69278\ttraining's multi_logloss: 0.69278\tvalid_1's multi_logloss: 0.774333\tvalid_1's multi_logloss: 0.774333\n",
      "[300]\ttraining's multi_logloss: 0.653517\ttraining's multi_logloss: 0.653517\tvalid_1's multi_logloss: 0.763178\tvalid_1's multi_logloss: 0.763178\n",
      "[400]\ttraining's multi_logloss: 0.62304\ttraining's multi_logloss: 0.62304\tvalid_1's multi_logloss: 0.756523\tvalid_1's multi_logloss: 0.756523\n",
      "[500]\ttraining's multi_logloss: 0.597562\ttraining's multi_logloss: 0.597562\tvalid_1's multi_logloss: 0.75112\tvalid_1's multi_logloss: 0.75112\n",
      "[600]\ttraining's multi_logloss: 0.574393\ttraining's multi_logloss: 0.574393\tvalid_1's multi_logloss: 0.746415\tvalid_1's multi_logloss: 0.746415\n",
      "[700]\ttraining's multi_logloss: 0.553762\ttraining's multi_logloss: 0.553762\tvalid_1's multi_logloss: 0.743361\tvalid_1's multi_logloss: 0.743361\n",
      "[800]\ttraining's multi_logloss: 0.535636\ttraining's multi_logloss: 0.535636\tvalid_1's multi_logloss: 0.741101\tvalid_1's multi_logloss: 0.741101\n",
      "[900]\ttraining's multi_logloss: 0.518494\ttraining's multi_logloss: 0.518494\tvalid_1's multi_logloss: 0.740053\tvalid_1's multi_logloss: 0.740053\n",
      "[1000]\ttraining's multi_logloss: 0.502668\ttraining's multi_logloss: 0.502668\tvalid_1's multi_logloss: 0.739151\tvalid_1's multi_logloss: 0.739151\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's multi_logloss: 0.502668\ttraining's multi_logloss: 0.502668\tvalid_1's multi_logloss: 0.739151\tvalid_1's multi_logloss: 0.739151\n"
     ]
    }
   ],
   "source": [
    "clf = train_all(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpmJSHRxCozY"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/content/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThfO2hoHCp4l"
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test.drop('index', axis=1))\n",
    "submission.iloc[:, 1:] = predictions\n",
    "submission.to_csv('submission_try02_tunning_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFveLon_Fm5z"
   },
   "source": [
    "#### 5-3. 최적의 파라미터로 OOF 검증하여 학습/예측 시행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsRPMfhHFj2H"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def train_apps_all_with_oof(train, test, nfolds=5):\n",
    "    ftr_train = train.drop(['index', 'credit'], axis=1)\n",
    "    target_train = train['credit']\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=2020)\n",
    "    \n",
    "    #  Out of Folds로 학습된 모델의 validation set을 예측하여 결과 확률을 담을 array 생성.\n",
    "    # validation set가 n_split갯수만큼 있으므로 크기는 ftr_app의 크기가 되어야 함. \n",
    "    # oof_preds = np.zeros(ftr_train.shape[0])  \n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros((test.shape[0], 3))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMClassifier(\n",
    "                  nthread=4,\n",
    "                  n_estimators=4000,\n",
    "                  learning_rate=0.01,\n",
    "                  max_depth = 15,\n",
    "                  num_leaves=58,\n",
    "                  colsample_bytree=0.870,\n",
    "                  subsample=0.674,\n",
    "                  max_bin=91,\n",
    "                  reg_alpha=1.841,\n",
    "                  reg_lambda=0.039,\n",
    "                  min_child_weight=2,\n",
    "                  min_child_samples=13,\n",
    "                  silent=-1,\n",
    "                  verbose=-1,\n",
    "                  )\n",
    "                  \n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr_train, target_train)):\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x  = ftr_train.iloc[train_idx, :]\n",
    "        train_y = target_train.iloc[train_idx]\n",
    "        valid_x = ftr_train.iloc[valid_idx, :]\n",
    "        valid_y = target_train.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "        # 검증 데이터 세트로 예측된 확률 저장. 사용되지는 않음. \n",
    "        # oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]       \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산. \n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict_proba(test.drop('index', axis=1), num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "        \n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1X-qktNFuEW",
    "outputId": "1a2ef2eb-807d-4d69-bc35-6b16d20cae2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration  0  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.74641\ttraining's multi_logloss: 0.74641\tvalid_1's multi_logloss: 0.794658\tvalid_1's multi_logloss: 0.794658\n",
      "[400]\ttraining's multi_logloss: 0.695127\ttraining's multi_logloss: 0.695127\tvalid_1's multi_logloss: 0.774351\tvalid_1's multi_logloss: 0.774351\n",
      "[600]\ttraining's multi_logloss: 0.660807\ttraining's multi_logloss: 0.660807\tvalid_1's multi_logloss: 0.764565\tvalid_1's multi_logloss: 0.764565\n",
      "[800]\ttraining's multi_logloss: 0.630844\ttraining's multi_logloss: 0.630844\tvalid_1's multi_logloss: 0.757602\tvalid_1's multi_logloss: 0.757602\n",
      "[1000]\ttraining's multi_logloss: 0.605362\ttraining's multi_logloss: 0.605362\tvalid_1's multi_logloss: 0.751738\tvalid_1's multi_logloss: 0.751738\n",
      "[1200]\ttraining's multi_logloss: 0.583417\ttraining's multi_logloss: 0.583417\tvalid_1's multi_logloss: 0.748062\tvalid_1's multi_logloss: 0.748062\n",
      "[1400]\ttraining's multi_logloss: 0.563644\ttraining's multi_logloss: 0.563644\tvalid_1's multi_logloss: 0.744123\tvalid_1's multi_logloss: 0.744123\n",
      "[1600]\ttraining's multi_logloss: 0.546173\ttraining's multi_logloss: 0.546173\tvalid_1's multi_logloss: 0.742087\tvalid_1's multi_logloss: 0.742087\n",
      "[1800]\ttraining's multi_logloss: 0.53035\ttraining's multi_logloss: 0.53035\tvalid_1's multi_logloss: 0.740805\tvalid_1's multi_logloss: 0.740805\n",
      "[2000]\ttraining's multi_logloss: 0.51504\ttraining's multi_logloss: 0.51504\tvalid_1's multi_logloss: 0.739797\tvalid_1's multi_logloss: 0.739797\n",
      "[2200]\ttraining's multi_logloss: 0.501068\ttraining's multi_logloss: 0.501068\tvalid_1's multi_logloss: 0.738585\tvalid_1's multi_logloss: 0.738585\n",
      "[2400]\ttraining's multi_logloss: 0.48794\ttraining's multi_logloss: 0.48794\tvalid_1's multi_logloss: 0.737565\tvalid_1's multi_logloss: 0.737565\n",
      "[2600]\ttraining's multi_logloss: 0.47525\ttraining's multi_logloss: 0.47525\tvalid_1's multi_logloss: 0.737296\tvalid_1's multi_logloss: 0.737296\n",
      "Early stopping, best iteration is:\n",
      "[2493]\ttraining's multi_logloss: 0.482069\ttraining's multi_logloss: 0.482069\tvalid_1's multi_logloss: 0.737195\tvalid_1's multi_logloss: 0.737195\n",
      "##### iteration  1  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.74833\ttraining's multi_logloss: 0.74833\tvalid_1's multi_logloss: 0.78844\tvalid_1's multi_logloss: 0.78844\n",
      "[400]\ttraining's multi_logloss: 0.697511\ttraining's multi_logloss: 0.697511\tvalid_1's multi_logloss: 0.766831\tvalid_1's multi_logloss: 0.766831\n",
      "[600]\ttraining's multi_logloss: 0.661598\ttraining's multi_logloss: 0.661598\tvalid_1's multi_logloss: 0.754102\tvalid_1's multi_logloss: 0.754102\n",
      "[800]\ttraining's multi_logloss: 0.631859\ttraining's multi_logloss: 0.631859\tvalid_1's multi_logloss: 0.745065\tvalid_1's multi_logloss: 0.745065\n",
      "[1000]\ttraining's multi_logloss: 0.606446\ttraining's multi_logloss: 0.606446\tvalid_1's multi_logloss: 0.739311\tvalid_1's multi_logloss: 0.739311\n",
      "[1200]\ttraining's multi_logloss: 0.583907\ttraining's multi_logloss: 0.583907\tvalid_1's multi_logloss: 0.734857\tvalid_1's multi_logloss: 0.734857\n",
      "[1400]\ttraining's multi_logloss: 0.563944\ttraining's multi_logloss: 0.563944\tvalid_1's multi_logloss: 0.730965\tvalid_1's multi_logloss: 0.730965\n",
      "[1600]\ttraining's multi_logloss: 0.546264\ttraining's multi_logloss: 0.546264\tvalid_1's multi_logloss: 0.728775\tvalid_1's multi_logloss: 0.728775\n",
      "[1800]\ttraining's multi_logloss: 0.529452\ttraining's multi_logloss: 0.529452\tvalid_1's multi_logloss: 0.727051\tvalid_1's multi_logloss: 0.727051\n",
      "[2000]\ttraining's multi_logloss: 0.513707\ttraining's multi_logloss: 0.513707\tvalid_1's multi_logloss: 0.725784\tvalid_1's multi_logloss: 0.725784\n",
      "[2200]\ttraining's multi_logloss: 0.499124\ttraining's multi_logloss: 0.499124\tvalid_1's multi_logloss: 0.725171\tvalid_1's multi_logloss: 0.725171\n",
      "[2400]\ttraining's multi_logloss: 0.485716\ttraining's multi_logloss: 0.485716\tvalid_1's multi_logloss: 0.724695\tvalid_1's multi_logloss: 0.724695\n",
      "[2600]\ttraining's multi_logloss: 0.473263\ttraining's multi_logloss: 0.473263\tvalid_1's multi_logloss: 0.724894\tvalid_1's multi_logloss: 0.724894\n",
      "Early stopping, best iteration is:\n",
      "[2417]\ttraining's multi_logloss: 0.48457\ttraining's multi_logloss: 0.48457\tvalid_1's multi_logloss: 0.724619\tvalid_1's multi_logloss: 0.724619\n",
      "##### iteration  2  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.74887\ttraining's multi_logloss: 0.74887\tvalid_1's multi_logloss: 0.786353\tvalid_1's multi_logloss: 0.786353\n",
      "[400]\ttraining's multi_logloss: 0.697423\ttraining's multi_logloss: 0.697423\tvalid_1's multi_logloss: 0.763558\tvalid_1's multi_logloss: 0.763558\n",
      "[600]\ttraining's multi_logloss: 0.662228\ttraining's multi_logloss: 0.662228\tvalid_1's multi_logloss: 0.752119\tvalid_1's multi_logloss: 0.752119\n",
      "[800]\ttraining's multi_logloss: 0.632895\ttraining's multi_logloss: 0.632895\tvalid_1's multi_logloss: 0.744089\tvalid_1's multi_logloss: 0.744089\n",
      "[1000]\ttraining's multi_logloss: 0.607821\ttraining's multi_logloss: 0.607821\tvalid_1's multi_logloss: 0.737612\tvalid_1's multi_logloss: 0.737612\n",
      "[1200]\ttraining's multi_logloss: 0.585625\ttraining's multi_logloss: 0.585625\tvalid_1's multi_logloss: 0.732883\tvalid_1's multi_logloss: 0.732883\n",
      "[1400]\ttraining's multi_logloss: 0.565648\ttraining's multi_logloss: 0.565648\tvalid_1's multi_logloss: 0.72884\tvalid_1's multi_logloss: 0.72884\n",
      "[1600]\ttraining's multi_logloss: 0.548053\ttraining's multi_logloss: 0.548053\tvalid_1's multi_logloss: 0.726643\tvalid_1's multi_logloss: 0.726643\n",
      "[1800]\ttraining's multi_logloss: 0.531714\ttraining's multi_logloss: 0.531714\tvalid_1's multi_logloss: 0.724264\tvalid_1's multi_logloss: 0.724264\n",
      "[2000]\ttraining's multi_logloss: 0.516073\ttraining's multi_logloss: 0.516073\tvalid_1's multi_logloss: 0.722523\tvalid_1's multi_logloss: 0.722523\n",
      "[2200]\ttraining's multi_logloss: 0.50199\ttraining's multi_logloss: 0.50199\tvalid_1's multi_logloss: 0.721113\tvalid_1's multi_logloss: 0.721113\n",
      "[2400]\ttraining's multi_logloss: 0.488366\ttraining's multi_logloss: 0.488366\tvalid_1's multi_logloss: 0.720218\tvalid_1's multi_logloss: 0.720218\n",
      "[2600]\ttraining's multi_logloss: 0.475152\ttraining's multi_logloss: 0.475152\tvalid_1's multi_logloss: 0.719472\tvalid_1's multi_logloss: 0.719472\n",
      "[2800]\ttraining's multi_logloss: 0.46324\ttraining's multi_logloss: 0.46324\tvalid_1's multi_logloss: 0.719108\tvalid_1's multi_logloss: 0.719108\n",
      "Early stopping, best iteration is:\n",
      "[2790]\ttraining's multi_logloss: 0.463804\ttraining's multi_logloss: 0.463804\tvalid_1's multi_logloss: 0.71907\tvalid_1's multi_logloss: 0.71907\n",
      "##### iteration  3  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.749253\ttraining's multi_logloss: 0.749253\tvalid_1's multi_logloss: 0.781564\tvalid_1's multi_logloss: 0.781564\n",
      "[400]\ttraining's multi_logloss: 0.697934\ttraining's multi_logloss: 0.697934\tvalid_1's multi_logloss: 0.758002\tvalid_1's multi_logloss: 0.758002\n",
      "[600]\ttraining's multi_logloss: 0.663015\ttraining's multi_logloss: 0.663015\tvalid_1's multi_logloss: 0.747689\tvalid_1's multi_logloss: 0.747689\n",
      "[800]\ttraining's multi_logloss: 0.632644\ttraining's multi_logloss: 0.632644\tvalid_1's multi_logloss: 0.738698\tvalid_1's multi_logloss: 0.738698\n",
      "[1000]\ttraining's multi_logloss: 0.606012\ttraining's multi_logloss: 0.606012\tvalid_1's multi_logloss: 0.730894\tvalid_1's multi_logloss: 0.730894\n",
      "[1200]\ttraining's multi_logloss: 0.583693\ttraining's multi_logloss: 0.583693\tvalid_1's multi_logloss: 0.725809\tvalid_1's multi_logloss: 0.725809\n",
      "[1400]\ttraining's multi_logloss: 0.563634\ttraining's multi_logloss: 0.563634\tvalid_1's multi_logloss: 0.72186\tvalid_1's multi_logloss: 0.72186\n",
      "[1600]\ttraining's multi_logloss: 0.545793\ttraining's multi_logloss: 0.545793\tvalid_1's multi_logloss: 0.719074\tvalid_1's multi_logloss: 0.719074\n",
      "[1800]\ttraining's multi_logloss: 0.528916\ttraining's multi_logloss: 0.528916\tvalid_1's multi_logloss: 0.717204\tvalid_1's multi_logloss: 0.717204\n",
      "[2000]\ttraining's multi_logloss: 0.513653\ttraining's multi_logloss: 0.513653\tvalid_1's multi_logloss: 0.71516\tvalid_1's multi_logloss: 0.71516\n",
      "[2200]\ttraining's multi_logloss: 0.499395\ttraining's multi_logloss: 0.499395\tvalid_1's multi_logloss: 0.713757\tvalid_1's multi_logloss: 0.713757\n",
      "[2400]\ttraining's multi_logloss: 0.48667\ttraining's multi_logloss: 0.48667\tvalid_1's multi_logloss: 0.712146\tvalid_1's multi_logloss: 0.712146\n",
      "[2600]\ttraining's multi_logloss: 0.474561\ttraining's multi_logloss: 0.474561\tvalid_1's multi_logloss: 0.712015\tvalid_1's multi_logloss: 0.712015\n",
      "Early stopping, best iteration is:\n",
      "[2457]\ttraining's multi_logloss: 0.483073\ttraining's multi_logloss: 0.483073\tvalid_1's multi_logloss: 0.711879\tvalid_1's multi_logloss: 0.711879\n",
      "##### iteration  4  시작\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's multi_logloss: 0.749816\ttraining's multi_logloss: 0.749816\tvalid_1's multi_logloss: 0.786283\tvalid_1's multi_logloss: 0.786283\n",
      "[400]\ttraining's multi_logloss: 0.698903\ttraining's multi_logloss: 0.698903\tvalid_1's multi_logloss: 0.7633\tvalid_1's multi_logloss: 0.7633\n",
      "[600]\ttraining's multi_logloss: 0.664431\ttraining's multi_logloss: 0.664431\tvalid_1's multi_logloss: 0.750436\tvalid_1's multi_logloss: 0.750436\n",
      "[800]\ttraining's multi_logloss: 0.634847\ttraining's multi_logloss: 0.634847\tvalid_1's multi_logloss: 0.740972\tvalid_1's multi_logloss: 0.740972\n",
      "[1000]\ttraining's multi_logloss: 0.610473\ttraining's multi_logloss: 0.610473\tvalid_1's multi_logloss: 0.733618\tvalid_1's multi_logloss: 0.733618\n",
      "[1200]\ttraining's multi_logloss: 0.588353\ttraining's multi_logloss: 0.588353\tvalid_1's multi_logloss: 0.72776\tvalid_1's multi_logloss: 0.72776\n",
      "[1400]\ttraining's multi_logloss: 0.567936\ttraining's multi_logloss: 0.567936\tvalid_1's multi_logloss: 0.722453\tvalid_1's multi_logloss: 0.722453\n",
      "[1600]\ttraining's multi_logloss: 0.550011\ttraining's multi_logloss: 0.550011\tvalid_1's multi_logloss: 0.718536\tvalid_1's multi_logloss: 0.718536\n",
      "[1800]\ttraining's multi_logloss: 0.534045\ttraining's multi_logloss: 0.534045\tvalid_1's multi_logloss: 0.716106\tvalid_1's multi_logloss: 0.716106\n",
      "[2000]\ttraining's multi_logloss: 0.519304\ttraining's multi_logloss: 0.519304\tvalid_1's multi_logloss: 0.713505\tvalid_1's multi_logloss: 0.713505\n",
      "[2200]\ttraining's multi_logloss: 0.5057\ttraining's multi_logloss: 0.5057\tvalid_1's multi_logloss: 0.711984\tvalid_1's multi_logloss: 0.711984\n",
      "[2400]\ttraining's multi_logloss: 0.49276\ttraining's multi_logloss: 0.49276\tvalid_1's multi_logloss: 0.710572\tvalid_1's multi_logloss: 0.710572\n",
      "[2600]\ttraining's multi_logloss: 0.480267\ttraining's multi_logloss: 0.480267\tvalid_1's multi_logloss: 0.709392\tvalid_1's multi_logloss: 0.709392\n",
      "[2800]\ttraining's multi_logloss: 0.468158\ttraining's multi_logloss: 0.468158\tvalid_1's multi_logloss: 0.708402\tvalid_1's multi_logloss: 0.708402\n",
      "[3000]\ttraining's multi_logloss: 0.456675\ttraining's multi_logloss: 0.456675\tvalid_1's multi_logloss: 0.707898\tvalid_1's multi_logloss: 0.707898\n",
      "[3200]\ttraining's multi_logloss: 0.446111\ttraining's multi_logloss: 0.446111\tvalid_1's multi_logloss: 0.707388\tvalid_1's multi_logloss: 0.707388\n",
      "[3400]\ttraining's multi_logloss: 0.436655\ttraining's multi_logloss: 0.436655\tvalid_1's multi_logloss: 0.706991\tvalid_1's multi_logloss: 0.706991\n",
      "[3600]\ttraining's multi_logloss: 0.427201\ttraining's multi_logloss: 0.427201\tvalid_1's multi_logloss: 0.707356\tvalid_1's multi_logloss: 0.707356\n",
      "Early stopping, best iteration is:\n",
      "[3411]\ttraining's multi_logloss: 0.436167\ttraining's multi_logloss: 0.436167\tvalid_1's multi_logloss: 0.706933\tvalid_1's multi_logloss: 0.706933\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(train, test, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V17yhjo1F_lM"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/content/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvvrQIAxGAHK"
   },
   "outputs": [],
   "source": [
    "submission.iloc[:, 1:] = test_preds\n",
    "submission.to_csv('submission_try02_tunning_3_2_oof.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bNuIcdXitE5d",
    "It6o1aN6r40g",
    "rnGApxXRtbn7",
    "ixZxI8-Wsz11"
   ],
   "name": "Dacon_user_credit_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
